{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "29834af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "880027d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
      "       'Embarked'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "PassengerId                                                                   \n",
       "882                 0       3    male  33.0      0      0            349257   \n",
       "883                 0       3  female  22.0      0      0              7552   \n",
       "884                 0       2    male  28.0      0      0  C.A./SOTON 34068   \n",
       "885                 0       3    male  25.0      0      0   SOTON/OQ 392076   \n",
       "886                 0       3  female  39.0      0      5            382652   \n",
       "887                 0       2    male  27.0      0      0            211536   \n",
       "888                 1       1  female  19.0      0      0            112053   \n",
       "889                 0       3  female   NaN      1      2        W./C. 6607   \n",
       "890                 1       1    male  26.0      0      0            111369   \n",
       "891                 0       3    male  32.0      0      0            370376   \n",
       "\n",
       "                Fare Embarked  \n",
       "PassengerId                    \n",
       "882           7.8958        S  \n",
       "883          10.5167        S  \n",
       "884          10.5000        S  \n",
       "885           7.0500        S  \n",
       "886          29.1250        Q  \n",
       "887          13.0000        S  \n",
       "888          30.0000        S  \n",
       "889          23.4500        S  \n",
       "890          30.0000        C  \n",
       "891           7.7500        Q  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\", index_col=0)\n",
    "df = df.drop_duplicates()\n",
    "df = df.drop(columns={\"Name\",\"Cabin\"})\n",
    "print(df.columns)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8b8b2257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Ticket        0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "(891, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4858af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Ticket        0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>521171.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23101282.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass     Sex   Age  SibSp  Parch      Ticket  \\\n",
       "PassengerId                                                             \n",
       "1                   0       3    male  22.0      1      0    521171.0   \n",
       "2                   1       1  female  38.0      1      0     17599.0   \n",
       "3                   1       3  female  26.0      0      0  23101282.0   \n",
       "4                   1       1  female  35.0      1      0    113803.0   \n",
       "5                   0       3    male  35.0      0      0    373450.0   \n",
       "...               ...     ...     ...   ...    ...    ...         ...   \n",
       "887                 0       2    male  27.0      0      0    211536.0   \n",
       "888                 1       1  female  19.0      0      0    112053.0   \n",
       "889                 0       3  female   NaN      1      2      6607.0   \n",
       "890                 1       1    male  26.0      0      0    111369.0   \n",
       "891                 0       3    male  32.0      0      0    370376.0   \n",
       "\n",
       "                Fare Embarked  \n",
       "PassengerId                    \n",
       "1             7.2500        S  \n",
       "2            71.2833        C  \n",
       "3             7.9250        S  \n",
       "4            53.1000        S  \n",
       "5             8.0500        S  \n",
       "...              ...      ...  \n",
       "887          13.0000        S  \n",
       "888          30.0000        S  \n",
       "889          23.4500        S  \n",
       "890          30.0000        C  \n",
       "891           7.7500        Q  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ticket'] = df['Ticket'].str.replace(r'\\D', '')\n",
    "df = df.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "for k in list(df):\n",
    "    df[\"Ticket\"]=pd.to_numeric(df[\"Ticket\"], errors='ignore')\n",
    "df[\"Ticket\"] = df[\"Ticket\"].interpolate(method='linear')\n",
    "print(df.isnull().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "734cea2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>521171.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23101282.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch      Ticket     Fare  \\\n",
       "PassengerId                                                                   \n",
       "1                   0       3    1  22.0      1      0    521171.0   7.2500   \n",
       "2                   1       1    0  38.0      1      0     17599.0  71.2833   \n",
       "3                   1       3    0  26.0      0      0  23101282.0   7.9250   \n",
       "4                   1       1    0  35.0      1      0    113803.0  53.1000   \n",
       "5                   0       3    1  35.0      0      0    373450.0   8.0500   \n",
       "...               ...     ...  ...   ...    ...    ...         ...      ...   \n",
       "887                 0       2    1  27.0      0      0    211536.0  13.0000   \n",
       "888                 1       1    0  19.0      0      0    112053.0  30.0000   \n",
       "889                 0       3    0   NaN      1      2      6607.0  23.4500   \n",
       "890                 1       1    1  26.0      0      0    111369.0  30.0000   \n",
       "891                 0       3    1  32.0      0      0    370376.0   7.7500   \n",
       "\n",
       "             Embarked  \n",
       "PassengerId            \n",
       "1                   2  \n",
       "2                   0  \n",
       "3                   2  \n",
       "4                   2  \n",
       "5                   2  \n",
       "...               ...  \n",
       "887                 2  \n",
       "888                 2  \n",
       "889                 2  \n",
       "890                 0  \n",
       "891                 1  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "df['Embarked'] = le.fit_transform(df['Embarked'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bfc4283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest allowed 9317247.5200265\n",
      "Lowest allowed -7806240.494212807\n",
      "             Survived  Pclass  Sex   Age  SibSp  Parch      Ticket    Fare  \\\n",
      "PassengerId                                                                  \n",
      "3                   1       3    0  26.0      0      0  23101282.0   7.925   \n",
      "116                 0       3    1  21.0      0      0  23101294.0   7.925   \n",
      "143                 1       3    0  24.0      1      0  23101279.0  15.850   \n",
      "174                 0       3    1  21.0      0      0  23101280.0   7.925   \n",
      "217                 1       3    0  27.0      0      0  23101283.0   7.925   \n",
      "244                 0       3    1  22.0      0      0  23101275.0   7.125   \n",
      "383                 0       3    1  32.0      0      0  23101293.0   7.925   \n",
      "401                 1       3    1  39.0      0      0  23101289.0   7.925   \n",
      "404                 0       3    1  28.0      1      0  23101279.0  15.850   \n",
      "415                 1       3    1  44.0      0      0  23101269.0   7.925   \n",
      "434                 0       3    1  17.0      0      0  23101274.0   7.125   \n",
      "580                 1       3    1  32.0      0      0  23101286.0   7.925   \n",
      "591                 0       3    1  35.0      0      0  23101273.0   7.125   \n",
      "637                 0       3    1  32.0      0      0  23101292.0   7.925   \n",
      "665                 1       3    1  20.0      1      0  23101285.0   7.925   \n",
      "730                 0       3    0  25.0      1      0  23101271.0   7.925   \n",
      "745                 1       3    1  31.0      0      0  23101288.0   7.925   \n",
      "762                 0       3    1  41.0      0      0  23101272.0   7.125   \n",
      "817                 0       3    0  23.0      0      0  23101290.0   7.925   \n",
      "841                 0       3    1  20.0      0      0  23101287.0   7.925   \n",
      "\n",
      "             Embarked  \n",
      "PassengerId            \n",
      "3                   2  \n",
      "116                 2  \n",
      "143                 2  \n",
      "174                 2  \n",
      "217                 2  \n",
      "244                 2  \n",
      "383                 2  \n",
      "401                 2  \n",
      "404                 2  \n",
      "415                 2  \n",
      "434                 2  \n",
      "580                 2  \n",
      "591                 2  \n",
      "637                 2  \n",
      "665                 2  \n",
      "730                 2  \n",
      "745                 2  \n",
      "762                 2  \n",
      "817                 2  \n",
      "841                 2  \n",
      "Highest allowed 158.0697154561741\n",
      "Lowest allowed -92.57534278108805\n",
      "             Survived  Pclass  Sex   Age  SibSp  Parch    Ticket      Fare  \\\n",
      "PassengerId                                                                  \n",
      "28                  0       1    1  19.0      3      2   19950.0  263.0000   \n",
      "89                  1       1    0  23.0      3      2   19950.0  263.0000   \n",
      "119                 0       1    1  24.0      0      1   17558.0  247.5208   \n",
      "259                 1       1    0  35.0      0      0   17755.0  512.3292   \n",
      "300                 1       1    0  50.0      0      1   17558.0  247.5208   \n",
      "312                 1       1    0  18.0      2      2   17608.0  262.3750   \n",
      "319                 1       1    0  31.0      0      2   36928.0  164.8667   \n",
      "342                 1       1    0  24.0      3      2   19950.0  263.0000   \n",
      "378                 0       1    1  27.0      0      2  113503.0  211.5000   \n",
      "381                 1       1    0  42.0      0      0   17757.0  227.5250   \n",
      "439                 0       1    1  64.0      1      4   19950.0  263.0000   \n",
      "528                 0       1    1   NaN      0      0   17483.0  221.7792   \n",
      "558                 0       1    1   NaN      0      0   17757.0  227.5250   \n",
      "680                 1       1    1  36.0      0      1   17755.0  512.3292   \n",
      "690                 1       1    0  15.0      0      1   24160.0  211.3375   \n",
      "701                 1       1    0  18.0      1      0   17757.0  227.5250   \n",
      "717                 1       1    0  38.0      0      0   17757.0  227.5250   \n",
      "731                 1       1    0  29.0      0      0   24160.0  211.3375   \n",
      "738                 1       1    1  35.0      0      0   17755.0  512.3292   \n",
      "743                 1       1    0  21.0      2      2   17608.0  262.3750   \n",
      "780                 1       1    0  43.0      0      1   24160.0  211.3375   \n",
      "857                 1       1    0  45.0      1      1   36928.0  164.8667   \n",
      "\n",
      "             Embarked  \n",
      "PassengerId            \n",
      "28                  2  \n",
      "89                  2  \n",
      "119                 0  \n",
      "259                 0  \n",
      "300                 0  \n",
      "312                 0  \n",
      "319                 2  \n",
      "342                 2  \n",
      "378                 0  \n",
      "381                 0  \n",
      "439                 2  \n",
      "528                 2  \n",
      "558                 0  \n",
      "680                 0  \n",
      "690                 2  \n",
      "701                 0  \n",
      "717                 0  \n",
      "731                 2  \n",
      "738                 0  \n",
      "743                 0  \n",
      "780                 2  \n",
      "857                 2  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>521171.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877.0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch    Ticket     Fare  \\\n",
       "PassengerId                                                                 \n",
       "1                   0       3    1  22.0      1      0  521171.0   7.2500   \n",
       "2                   1       1    0  38.0      1      0   17599.0  71.2833   \n",
       "4                   1       1    0  35.0      1      0  113803.0  53.1000   \n",
       "5                   0       3    1  35.0      0      0  373450.0   8.0500   \n",
       "6                   0       3    1   NaN      0      0  330877.0   8.4583   \n",
       "...               ...     ...  ...   ...    ...    ...       ...      ...   \n",
       "887                 0       2    1  27.0      0      0  211536.0  13.0000   \n",
       "888                 1       1    0  19.0      0      0  112053.0  30.0000   \n",
       "889                 0       3    0   NaN      1      2    6607.0  23.4500   \n",
       "890                 1       1    1  26.0      0      0  111369.0  30.0000   \n",
       "891                 0       3    1  32.0      0      0  370376.0   7.7500   \n",
       "\n",
       "             Embarked  \n",
       "PassengerId            \n",
       "1                   2  \n",
       "2                   0  \n",
       "4                   2  \n",
       "5                   2  \n",
       "6                   1  \n",
       "...               ...  \n",
       "887                 2  \n",
       "888                 2  \n",
       "889                 2  \n",
       "890                 0  \n",
       "891                 1  \n",
       "\n",
       "[849 rows x 9 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HA = df['Ticket'].mean() + 2.5*df['Ticket'].std()\n",
    "LA = df['Ticket'].mean() - 2.5*df['Ticket'].std()\n",
    "print(\"Highest allowed\", HA)\n",
    "print(\"Lowest allowed\", LA)\n",
    "print(df[(df['Ticket'] > HA) | (df['Ticket'] < LA)])\n",
    "df = df[(df['Ticket'] < HA) & (df['Ticket'] > LA)]\n",
    "\n",
    "HA2 = df['Fare'].mean() + 2.5*df['Fare'].std()\n",
    "LA2 = df['Fare'].mean() - 2.5*df['Fare'].std()\n",
    "print(\"Highest allowed\", HA2)\n",
    "print(\"Lowest allowed\", LA2)\n",
    "print(df[(df['Fare'] > HA2) | (df['Fare'] < LA2)])\n",
    "df = df[(df['Fare'] < HA2) & (df['Fare'] > LA2)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "96787bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Em_Sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751.0</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765.0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3381.0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534.0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767.0</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552.0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34068.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>392076.0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652.0</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch    Ticket     Fare  \\\n",
       "PassengerId                                                                 \n",
       "872                 1       1    0  47.0      1      1   11751.0  52.5542   \n",
       "873                 0       1    1  33.0      0      0     695.0   5.0000   \n",
       "874                 0       3    1  47.0      0      0  345765.0   9.0000   \n",
       "875                 1       2    0  28.0      1      0    3381.0  24.0000   \n",
       "876                 1       3    0  15.0      0      0    2667.0   7.2250   \n",
       "877                 0       3    1  20.0      0      0    7534.0   9.8458   \n",
       "878                 0       3    1  19.0      0      0  349212.0   7.8958   \n",
       "879                 0       3    1   NaN      0      0  349217.0   7.8958   \n",
       "880                 1       1    0  56.0      0      1   11767.0  83.1583   \n",
       "881                 1       2    0  25.0      0      1  230433.0  26.0000   \n",
       "882                 0       3    1  33.0      0      0  349257.0   7.8958   \n",
       "883                 0       3    0  22.0      0      0    7552.0  10.5167   \n",
       "884                 0       2    1  28.0      0      0   34068.0  10.5000   \n",
       "885                 0       3    1  25.0      0      0  392076.0   7.0500   \n",
       "886                 0       3    0  39.0      0      5  382652.0  29.1250   \n",
       "887                 0       2    1  27.0      0      0  211536.0  13.0000   \n",
       "888                 1       1    0  19.0      0      0  112053.0  30.0000   \n",
       "889                 0       3    0   NaN      1      2    6607.0  23.4500   \n",
       "890                 1       1    1  26.0      0      0  111369.0  30.0000   \n",
       "891                 0       3    1  32.0      0      0  370376.0   7.7500   \n",
       "\n",
       "             Embarked  Em_Sex  \n",
       "PassengerId                    \n",
       "872                 2     2.0  \n",
       "873                 2     5.0  \n",
       "874                 2     5.0  \n",
       "875                 0     0.0  \n",
       "876                 0     0.0  \n",
       "877                 2     5.0  \n",
       "878                 2     5.0  \n",
       "879                 2     5.0  \n",
       "880                 0     0.0  \n",
       "881                 2     2.0  \n",
       "882                 2     5.0  \n",
       "883                 2     2.0  \n",
       "884                 2     5.0  \n",
       "885                 2     5.0  \n",
       "886                 1     1.0  \n",
       "887                 2     5.0  \n",
       "888                 2     2.0  \n",
       "889                 2     2.0  \n",
       "890                 0     3.0  \n",
       "891                 1     4.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df[\"Embarked\"] == 0) & (df[\"Sex\"] == 0), \"Em_Sex\"] = 0  \n",
    "df.loc[(df[\"Embarked\"] == 1) & (df[\"Sex\"] == 0), \"Em_Sex\"] = 1  \n",
    "df.loc[(df[\"Embarked\"] == 2) & (df[\"Sex\"] == 0), \"Em_Sex\"] = 2  \n",
    "df.loc[(df[\"Embarked\"] == 0) & (df[\"Sex\"] == 1), \"Em_Sex\"] = 3  \n",
    "df.loc[(df[\"Embarked\"] == 1) & (df[\"Sex\"] == 1), \"Em_Sex\"] = 4  \n",
    "df.loc[(df[\"Embarked\"] == 2) & (df[\"Sex\"] == 1), \"Em_Sex\"] = 5  \n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "76cea105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"Pclass\"] == 0) & (df[\"Sex\"] == 0), \"Pclass_Sex\"] = 0  \n",
    "df.loc[(df[\"Pclass\"] == 1) & (df[\"Sex\"] == 0), \"Pclass_Sex\"] = 1  \n",
    "df.loc[(df[\"Pclass\"] == 2) & (df[\"Sex\"] == 0), \"Pclass_Sex\"] = 2\n",
    "df.loc[(df[\"Pclass\"] == 3) & (df[\"Sex\"] == 0), \"Pclass_Sex\"] = 3  \n",
    "df.loc[(df[\"Pclass\"] == 0) & (df[\"Sex\"] == 1), \"Pclass_Sex\"] = 4  \n",
    "df.loc[(df[\"Pclass\"] == 1) & (df[\"Sex\"] == 1), \"Pclass_Sex\"] = 5  \n",
    "df.loc[(df[\"Pclass\"] == 2) & (df[\"Sex\"] == 1), \"Pclass_Sex\"] = 6\n",
    "df.loc[(df[\"Pclass\"] == 3) & (df[\"Sex\"] == 1), \"Pclass_Sex\"] = 7  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ed762c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 177\n",
      "Missing: 0\n",
      "Mean Accuracy: 1.000 (0.001)\n"
     ]
    }
   ],
   "source": [
    "# iterative imputation transform for the horse colic dataset\n",
    "from numpy import isnan, mean, std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "# load dataset\n",
    "# split into input and output elements\n",
    "data = df.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 11]\n",
    "X, y = data[:, ix], data[:, 10]\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "# define imputer\n",
    "imputer = IterativeImputer()\n",
    "#define modeling pipeline\n",
    "## model = svm.SVC(kernel='rbf', degree =3, gamma = 0.01, C = 100, max_iter=-1, random_state = 262)\n",
    "model = BaggingRegressor()\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "df = imputer.transform(X)\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(df).flatten()))\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "# define model evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2cabaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.columns = [\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\", \"Embarked\",\"Em_Sex\",\"Pclass_Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7d006f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age           0\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Ticket        0\n",
      "Fare          0\n",
      "Embarked      0\n",
      "Em_Sex        0\n",
      "Pclass_Sex    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Em_Sex</th>\n",
       "      <th>Pclass_Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349257.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7552.0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34068.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392076.0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>382652.0</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.416047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex        Age  SibSp  Parch    Ticket     Fare  \\\n",
       "839       0.0     3.0  1.0  33.000000    0.0    0.0  349257.0   7.8958   \n",
       "840       0.0     3.0  0.0  22.000000    0.0    0.0    7552.0  10.5167   \n",
       "841       0.0     2.0  1.0  28.000000    0.0    0.0   34068.0  10.5000   \n",
       "842       0.0     3.0  1.0  25.000000    0.0    0.0  392076.0   7.0500   \n",
       "843       0.0     3.0  0.0  39.000000    0.0    5.0  382652.0  29.1250   \n",
       "844       0.0     2.0  1.0  27.000000    0.0    0.0  211536.0  13.0000   \n",
       "845       1.0     1.0  0.0  19.000000    0.0    0.0  112053.0  30.0000   \n",
       "846       0.0     3.0  0.0  23.416047    1.0    2.0    6607.0  23.4500   \n",
       "847       1.0     1.0  1.0  26.000000    0.0    0.0  111369.0  30.0000   \n",
       "848       0.0     3.0  1.0  32.000000    0.0    0.0  370376.0   7.7500   \n",
       "\n",
       "     Embarked  Em_Sex  Pclass_Sex  \n",
       "839       2.0     5.0         7.0  \n",
       "840       2.0     2.0         3.0  \n",
       "841       2.0     5.0         6.0  \n",
       "842       2.0     5.0         7.0  \n",
       "843       1.0     1.0         3.0  \n",
       "844       2.0     5.0         6.0  \n",
       "845       2.0     2.0         1.0  \n",
       "846       2.0     2.0         3.0  \n",
       "847       0.0     3.0         5.0  \n",
       "848       1.0     4.0         7.0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "411ad24e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"Family\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "df.loc[df[\"Family\"] < 1, \"Family\"] = 0\n",
    "df.loc[df[\"Family\"] == 1, \"Family\"] = 1\n",
    "df.loc[(df[\"Family\"] > 1) & (df[\"Family\"] <= 3), \"Family\"] = 2\n",
    "df.loc[df[\"Family\"] > 3, \"Family\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ad8554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Alone\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "df.loc[df[\"Alone\"] < 1, \"Alone\"] = 0\n",
    "df.loc[df[\"Alone\"] >= 1, \"Alone\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e035276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Age\"] <= 5, \"Age\"] = 0\n",
    "df.loc[(df[\"Age\"] > 5) & (df[\"Age\"] <= 10), \"Age\"] = 1\n",
    "df.loc[(df[\"Age\"] > 10) & (df[\"Age\"] <= 25), \"Age\"] = 2\n",
    "df.loc[(df[\"Age\"] > 25) & (df[\"Age\"] <= 30), \"Age\"] = 3\n",
    "df.loc[(df[\"Age\"] > 30) & (df[\"Age\"] <= 40), \"Age\"] = 4\n",
    "df.loc[df[\"Age\"] > 40, \"Age\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a47db0cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d3555043a425>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                                 \u001b[0mcaching\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                                 n_jobs=-1)\n\u001b[1;32m---> 28\u001b[1;33m   \u001b[0mselector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Survived\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m   \u001b[0mgenfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Survived\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m   \u001b[0mgenfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenfeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\genetic_selection\\gscv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \"\"\"\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\genetic_selection\\gscv.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Selecting features with genetic algorithm.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         _, log = _eaFunction(pop, toolbox, cxpb=self.crossover_proba, mutpb=self.mutation_proba,\n\u001b[0m\u001b[0;32m    345\u001b[0m                              \u001b[0mngen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_generations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngen_no_change\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gen_no_change\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                              stats=stats, halloffame=hof, verbose=self.verbose)\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\genetic_selection\\gscv.py\u001b[0m in \u001b[0;36m_eaFunction\u001b[1;34m(population, toolbox, cxpb, mutpb, ngen, ngen_no_change, stats, halloffame, verbose)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# Evaluate the individuals with an invalid fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mfitnesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         '''\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "mcc = make_scorer(matthews_corrcoef)\n",
    "estimator = BaggingRegressor()\n",
    "from sklearn.model_selection import *\n",
    "report = pd.DataFrame()\n",
    "nofeats = [] \n",
    "chosen_feats = [] \n",
    "cvscore = [] \n",
    "rkf = RepeatedStratifiedKFold(n_repeats = 2, n_splits = 10)\n",
    "for i in range(2,11):\n",
    "  \n",
    "  selector = GeneticSelectionCV(estimator,\n",
    "                                cv = rkf,\n",
    "                                verbose = 0,\n",
    "                                scoring = mcc,\n",
    "                                max_features = i,\n",
    "                                n_population = 200,\n",
    "                                crossover_proba = 0.5,\n",
    "                                mutation_proba = 0.2,\n",
    "                                n_generations = 10,\n",
    "                                crossover_independent_proba=0.5,\n",
    "                                mutation_independent_proba=0.05,\n",
    "                                #tournament_size = 3,\n",
    "                                n_gen_no_change=10,\n",
    "                                caching=True,\n",
    "                                n_jobs=-1)\n",
    "  selector = selector.fit(df.drop(columns=\"Survived\"), y)\n",
    "  genfeats = df.drop(columns=\"Survived\").columns[selector.support_]\n",
    "  genfeats = list(genfeats)\n",
    "  print(\"Chosen Feats:  \", genfeats)\n",
    "\n",
    "  cv_score = selector.generation_scores_[-1]\n",
    "  nofeats.append(len(genfeats)) \n",
    "  chosen_feats.append(genfeats) \n",
    "  cvscore.append(cv_score)\n",
    "report[\"No of Feats\"] = nofeats\n",
    "report[\"Chosen Feats\"] = chosen_feats\n",
    "report[\"Scores\"] = cvscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4982c1e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      float64\n",
      "Pclass        float64\n",
      "Sex           float64\n",
      "Age           float64\n",
      "SibSp         float64\n",
      "Parch         float64\n",
      "Ticket        float64\n",
      "Fare          float64\n",
      "Embarked      float64\n",
      "Em_Sex        float64\n",
      "Pclass_Sex    float64\n",
      "Family        float64\n",
      "Alone         float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_Sex</th>\n",
       "      <th>Family</th>\n",
       "      <th>Alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>521171.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330877.0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  SibSp    Ticket     Fare  Pclass_Sex  Family  Alone\n",
       "0    2.0    1.0  521171.0   7.2500         7.0     1.0    1.0\n",
       "1    4.0    1.0   17599.0  71.2833         1.0     1.0    1.0\n",
       "2    4.0    1.0  113803.0  53.1000         1.0     1.0    1.0\n",
       "3    4.0    0.0  373450.0   8.0500         7.0     0.0    0.0\n",
       "4    3.0    0.0  330877.0   8.4583         7.0     0.0    0.0\n",
       "..   ...    ...       ...      ...         ...     ...    ...\n",
       "844  3.0    0.0  211536.0  13.0000         6.0     0.0    0.0\n",
       "845  2.0    0.0  112053.0  30.0000         1.0     0.0    0.0\n",
       "846  2.0    1.0    6607.0  23.4500         3.0     2.0    1.0\n",
       "847  3.0    0.0  111369.0  30.0000         5.0     0.0    0.0\n",
       "848  4.0    0.0  370376.0   7.7500         7.0     0.0    0.0\n",
       "\n",
       "[849 rows x 7 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[\"Survived\"] = df[\"Survived\"].astype(int)\n",
    "print(df.dtypes)\n",
    "X = df[[\"Age\",\"SibSp\",\"Ticket\",\"Fare\",\"Pclass_Sex\",\"Family\",\"Alone\"]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "113db2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived\n",
       "0         0.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "..        ...\n",
       "844       0.0\n",
       "845       1.0\n",
       "846       0.0\n",
       "847       1.0\n",
       "848       0.0\n",
       "\n",
       "[849 rows x 1 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[[\"Survived\"]]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "676742c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7055853 , -0.46231695, -0.47226929, ..., -0.89297496,\n",
       "        -0.70226867, -0.8005523 ],\n",
       "       [ 0.7573036 ,  0.38006424, -0.42703695, ...,  0.48834568,\n",
       "         1.3276466 ,  1.24913763],\n",
       "       [-0.7055853 , -0.46231695, -0.48142602, ...,  0.9487859 ,\n",
       "        -0.70226867, -0.8005523 ],\n",
       "       ...,\n",
       "       [-0.7055853 ,  1.22244542, -0.45867063, ...,  0.48834568,\n",
       "         1.3276466 ,  1.24913763],\n",
       "       [-0.7055853 ,  0.38006424, -0.45332658, ..., -1.81385539,\n",
       "         0.31268897,  1.24913763],\n",
       "       [ 0.02585915, -0.46231695,  0.16196548, ...,  0.9487859 ,\n",
       "        -0.70226867, -0.8005523 ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "#split dataset into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7, stratify=df[\"Sex\"],\n",
    "                                                    random_state=262)\n",
    "mmsc = MinMaxScaler(feature_range=(0, 1))\n",
    "stdscl = StandardScaler()\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=262)\n",
    "X_train = stdscl.fit_transform(X_train)\n",
    "X_test = stdscl.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9c440af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of: 0.857 (0.064)\n"
     ]
    }
   ],
   "source": [
    "##### from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "import sklearn.metrics as metrics\n",
    "cv = KFold(n_splits=20, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#A = {0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3,4,5,6,10,15,20,100}\n",
    "#A = {0.1,0.2,0.4,0.65,0.68,0.69,0.7,0.71,0.72,0.73,0.75,0.8,0.85,0.9}\n",
    "#A = {0.380,0.381,0.382,0.385,0.39,0.4,0.41,0.42}\n",
    "xgb = XGBClassifier(use_label_encoder=False, base_score=0.25, booster='gbtree', eta=0.381, max_depth=5, min_child_weight=6,\n",
    "                                max_delta_step=0.7, subsample=0.7, colsample_bytree=1, colsample_bylevel=0.7, colsample_bynode=1, \n",
    "                                reg_lambda=0, reg_alpha=1, tree_method=\"exact\", sketch_eps=0.1, scale_pos_weight=1.6, \n",
    "                                objective=\"binary:logitraw\", gamma=0.8, n_estimators=27, rate_drop=0.1, skip_drop=0.1,\n",
    "                                random_state = 262, n_jobs=-1)\n",
    "model = xgb\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy of: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "056ced1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"rate_drop\", \"skip_drop\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.4.0, the default evaluation metric used with the objective 'binary:logitraw' was changed from 'auc' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train precision= 0.905\n",
      "test precision= 0.8\n",
      "train f1 score= 0.885\n",
      "test f1 score= 0.795\n",
      "train accuracy score= 0.896\n",
      "test accuracy score= 0.812\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "print(\"train precision=\", np.round(metrics.precision_score(y_train, y_pred_xgb_train, average='macro'),3))\n",
    "print(\"test precision=\", np.round(metrics.precision_score(y_test, y_pred_xgb_test, average='macro'),3))\n",
    "f1_train = f1_score(y_train, y_pred_xgb_train, average='macro')\n",
    "f1_test = f1_score(y_test, y_pred_xgb_test, average='macro')\n",
    "print(\"train f1 score=\", np.round(f1_train,3))\n",
    "print(\"test f1 score=\", np.round(f1_test,3))\n",
    "Accuracy_train = accuracy_score(y_train, y_pred_xgb_train)\n",
    "Accuracy_test = accuracy_score(y_test, y_pred_xgb_test)\n",
    "print(\"train accuracy score=\", np.round(Accuracy_train,3))\n",
    "print(\"test accuracy score=\", np.round(Accuracy_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9609018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## print(xgb.feature_importances_)\n",
    "import matplotlib.pyplot as mp\n",
    "mp.bar(range(len(xgb.feature_importances_)), xgb.feature_importances_)\n",
    "mp.show()\n",
    "# plot feature importance\n",
    "from xgboost import plot_importance\n",
    "plot_importance(xgb)\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "23ce6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862 (0.059)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "import sklearn.metrics as metrics\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "cv = KFold(n_splits=20, random_state=262, shuffle=True)\n",
    "# create model\n",
    "#for i in range(500,4000,500):\n",
    "catb = CatBoostClassifier() #depth=16\n",
    "model = catb\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c052a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.008248\n",
      "0:\tlearn: 0.6871465\ttotal: 1.84ms\tremaining: 1.84s\n",
      "1:\tlearn: 0.6829635\ttotal: 3.01ms\tremaining: 1.5s\n",
      "2:\tlearn: 0.6774177\ttotal: 4.64ms\tremaining: 1.54s\n",
      "3:\tlearn: 0.6725409\ttotal: 6.04ms\tremaining: 1.5s\n",
      "4:\tlearn: 0.6672309\ttotal: 7.41ms\tremaining: 1.47s\n",
      "5:\tlearn: 0.6627562\ttotal: 9.16ms\tremaining: 1.52s\n",
      "6:\tlearn: 0.6579733\ttotal: 11.4ms\tremaining: 1.62s\n",
      "7:\tlearn: 0.6535071\ttotal: 12.8ms\tremaining: 1.59s\n",
      "8:\tlearn: 0.6486392\ttotal: 14.2ms\tremaining: 1.57s\n",
      "9:\tlearn: 0.6434998\ttotal: 16ms\tremaining: 1.59s\n",
      "10:\tlearn: 0.6384441\ttotal: 17.6ms\tremaining: 1.58s\n",
      "11:\tlearn: 0.6341802\ttotal: 19.2ms\tremaining: 1.58s\n",
      "12:\tlearn: 0.6297255\ttotal: 21ms\tremaining: 1.59s\n",
      "13:\tlearn: 0.6253767\ttotal: 22.6ms\tremaining: 1.59s\n",
      "14:\tlearn: 0.6207159\ttotal: 24.3ms\tremaining: 1.59s\n",
      "15:\tlearn: 0.6161807\ttotal: 26.3ms\tremaining: 1.61s\n",
      "16:\tlearn: 0.6129970\ttotal: 27ms\tremaining: 1.56s\n",
      "17:\tlearn: 0.6094119\ttotal: 27.9ms\tremaining: 1.52s\n",
      "18:\tlearn: 0.6047460\ttotal: 29.3ms\tremaining: 1.51s\n",
      "19:\tlearn: 0.6020994\ttotal: 30.1ms\tremaining: 1.48s\n",
      "20:\tlearn: 0.5978611\ttotal: 31.5ms\tremaining: 1.47s\n",
      "21:\tlearn: 0.5930937\ttotal: 33.4ms\tremaining: 1.48s\n",
      "22:\tlearn: 0.5889545\ttotal: 35.2ms\tremaining: 1.49s\n",
      "23:\tlearn: 0.5860634\ttotal: 36.9ms\tremaining: 1.5s\n",
      "24:\tlearn: 0.5824114\ttotal: 38.4ms\tremaining: 1.5s\n",
      "25:\tlearn: 0.5793643\ttotal: 40.5ms\tremaining: 1.52s\n",
      "26:\tlearn: 0.5755287\ttotal: 42.1ms\tremaining: 1.51s\n",
      "27:\tlearn: 0.5729796\ttotal: 43.2ms\tremaining: 1.5s\n",
      "28:\tlearn: 0.5698011\ttotal: 44.6ms\tremaining: 1.49s\n",
      "29:\tlearn: 0.5662081\ttotal: 46.1ms\tremaining: 1.49s\n",
      "30:\tlearn: 0.5630185\ttotal: 47.8ms\tremaining: 1.49s\n",
      "31:\tlearn: 0.5595437\ttotal: 49.5ms\tremaining: 1.5s\n",
      "32:\tlearn: 0.5567384\ttotal: 65.2ms\tremaining: 1.91s\n",
      "33:\tlearn: 0.5538026\ttotal: 67.2ms\tremaining: 1.91s\n",
      "34:\tlearn: 0.5508713\ttotal: 68.8ms\tremaining: 1.9s\n",
      "35:\tlearn: 0.5481866\ttotal: 70.3ms\tremaining: 1.88s\n",
      "36:\tlearn: 0.5451847\ttotal: 72.3ms\tremaining: 1.88s\n",
      "37:\tlearn: 0.5423182\ttotal: 74ms\tremaining: 1.87s\n",
      "38:\tlearn: 0.5390495\ttotal: 75.6ms\tremaining: 1.86s\n",
      "39:\tlearn: 0.5362530\ttotal: 77ms\tremaining: 1.85s\n",
      "40:\tlearn: 0.5335419\ttotal: 78.5ms\tremaining: 1.83s\n",
      "41:\tlearn: 0.5301742\ttotal: 80ms\tremaining: 1.82s\n",
      "42:\tlearn: 0.5274858\ttotal: 81.8ms\tremaining: 1.82s\n",
      "43:\tlearn: 0.5249178\ttotal: 83.6ms\tremaining: 1.82s\n",
      "44:\tlearn: 0.5222111\ttotal: 85.2ms\tremaining: 1.81s\n",
      "45:\tlearn: 0.5203096\ttotal: 87.3ms\tremaining: 1.81s\n",
      "46:\tlearn: 0.5179499\ttotal: 88.9ms\tremaining: 1.8s\n",
      "47:\tlearn: 0.5163956\ttotal: 89.9ms\tremaining: 1.78s\n",
      "48:\tlearn: 0.5140859\ttotal: 91.6ms\tremaining: 1.78s\n",
      "49:\tlearn: 0.5120829\ttotal: 93.7ms\tremaining: 1.78s\n",
      "50:\tlearn: 0.5095992\ttotal: 95.7ms\tremaining: 1.78s\n",
      "51:\tlearn: 0.5075488\ttotal: 97.5ms\tremaining: 1.78s\n",
      "52:\tlearn: 0.5052091\ttotal: 99.2ms\tremaining: 1.77s\n",
      "53:\tlearn: 0.5033468\ttotal: 101ms\tremaining: 1.77s\n",
      "54:\tlearn: 0.5009968\ttotal: 103ms\tremaining: 1.77s\n",
      "55:\tlearn: 0.4988852\ttotal: 105ms\tremaining: 1.77s\n",
      "56:\tlearn: 0.4965616\ttotal: 106ms\tremaining: 1.76s\n",
      "57:\tlearn: 0.4946712\ttotal: 108ms\tremaining: 1.75s\n",
      "58:\tlearn: 0.4928605\ttotal: 109ms\tremaining: 1.74s\n",
      "59:\tlearn: 0.4905376\ttotal: 111ms\tremaining: 1.74s\n",
      "60:\tlearn: 0.4886333\ttotal: 113ms\tremaining: 1.73s\n",
      "61:\tlearn: 0.4864535\ttotal: 114ms\tremaining: 1.72s\n",
      "62:\tlearn: 0.4853686\ttotal: 115ms\tremaining: 1.71s\n",
      "63:\tlearn: 0.4831488\ttotal: 116ms\tremaining: 1.7s\n",
      "64:\tlearn: 0.4816884\ttotal: 118ms\tremaining: 1.7s\n",
      "65:\tlearn: 0.4800488\ttotal: 119ms\tremaining: 1.69s\n",
      "66:\tlearn: 0.4783867\ttotal: 121ms\tremaining: 1.69s\n",
      "67:\tlearn: 0.4765473\ttotal: 123ms\tremaining: 1.68s\n",
      "68:\tlearn: 0.4746943\ttotal: 124ms\tremaining: 1.67s\n",
      "69:\tlearn: 0.4732121\ttotal: 125ms\tremaining: 1.67s\n",
      "70:\tlearn: 0.4712081\ttotal: 127ms\tremaining: 1.66s\n",
      "71:\tlearn: 0.4696075\ttotal: 128ms\tremaining: 1.66s\n",
      "72:\tlearn: 0.4684950\ttotal: 130ms\tremaining: 1.65s\n",
      "73:\tlearn: 0.4677423\ttotal: 130ms\tremaining: 1.63s\n",
      "74:\tlearn: 0.4658159\ttotal: 132ms\tremaining: 1.62s\n",
      "75:\tlearn: 0.4644360\ttotal: 133ms\tremaining: 1.62s\n",
      "76:\tlearn: 0.4633195\ttotal: 135ms\tremaining: 1.61s\n",
      "77:\tlearn: 0.4616030\ttotal: 136ms\tremaining: 1.61s\n",
      "78:\tlearn: 0.4600725\ttotal: 138ms\tremaining: 1.6s\n",
      "79:\tlearn: 0.4587289\ttotal: 139ms\tremaining: 1.6s\n",
      "80:\tlearn: 0.4575373\ttotal: 141ms\tremaining: 1.59s\n",
      "81:\tlearn: 0.4562584\ttotal: 142ms\tremaining: 1.59s\n",
      "82:\tlearn: 0.4545201\ttotal: 144ms\tremaining: 1.58s\n",
      "83:\tlearn: 0.4534142\ttotal: 145ms\tremaining: 1.58s\n",
      "84:\tlearn: 0.4521108\ttotal: 147ms\tremaining: 1.58s\n",
      "85:\tlearn: 0.4507267\ttotal: 149ms\tremaining: 1.58s\n",
      "86:\tlearn: 0.4491520\ttotal: 150ms\tremaining: 1.58s\n",
      "87:\tlearn: 0.4476729\ttotal: 152ms\tremaining: 1.58s\n",
      "88:\tlearn: 0.4464285\ttotal: 154ms\tremaining: 1.58s\n",
      "89:\tlearn: 0.4458429\ttotal: 156ms\tremaining: 1.57s\n",
      "90:\tlearn: 0.4447939\ttotal: 157ms\tremaining: 1.57s\n",
      "91:\tlearn: 0.4429607\ttotal: 159ms\tremaining: 1.57s\n",
      "92:\tlearn: 0.4414502\ttotal: 161ms\tremaining: 1.57s\n",
      "93:\tlearn: 0.4401732\ttotal: 162ms\tremaining: 1.56s\n",
      "94:\tlearn: 0.4383378\ttotal: 163ms\tremaining: 1.56s\n",
      "95:\tlearn: 0.4370461\ttotal: 166ms\tremaining: 1.56s\n",
      "96:\tlearn: 0.4359435\ttotal: 167ms\tremaining: 1.55s\n",
      "97:\tlearn: 0.4347395\ttotal: 169ms\tremaining: 1.55s\n",
      "98:\tlearn: 0.4337674\ttotal: 171ms\tremaining: 1.55s\n",
      "99:\tlearn: 0.4325707\ttotal: 172ms\tremaining: 1.55s\n",
      "100:\tlearn: 0.4313125\ttotal: 174ms\tremaining: 1.55s\n",
      "101:\tlearn: 0.4300265\ttotal: 176ms\tremaining: 1.55s\n",
      "102:\tlearn: 0.4287971\ttotal: 178ms\tremaining: 1.55s\n",
      "103:\tlearn: 0.4276955\ttotal: 179ms\tremaining: 1.54s\n",
      "104:\tlearn: 0.4267036\ttotal: 181ms\tremaining: 1.54s\n",
      "105:\tlearn: 0.4254927\ttotal: 182ms\tremaining: 1.54s\n",
      "106:\tlearn: 0.4244446\ttotal: 184ms\tremaining: 1.53s\n",
      "107:\tlearn: 0.4230139\ttotal: 185ms\tremaining: 1.53s\n",
      "108:\tlearn: 0.4218985\ttotal: 187ms\tremaining: 1.53s\n",
      "109:\tlearn: 0.4210855\ttotal: 188ms\tremaining: 1.52s\n",
      "110:\tlearn: 0.4202706\ttotal: 190ms\tremaining: 1.52s\n",
      "111:\tlearn: 0.4192658\ttotal: 191ms\tremaining: 1.51s\n",
      "112:\tlearn: 0.4178522\ttotal: 193ms\tremaining: 1.51s\n",
      "113:\tlearn: 0.4169912\ttotal: 194ms\tremaining: 1.51s\n",
      "114:\tlearn: 0.4161061\ttotal: 195ms\tremaining: 1.5s\n",
      "115:\tlearn: 0.4149116\ttotal: 197ms\tremaining: 1.5s\n",
      "116:\tlearn: 0.4139100\ttotal: 199ms\tremaining: 1.5s\n",
      "117:\tlearn: 0.4130178\ttotal: 200ms\tremaining: 1.5s\n",
      "118:\tlearn: 0.4122933\ttotal: 202ms\tremaining: 1.5s\n",
      "119:\tlearn: 0.4113553\ttotal: 203ms\tremaining: 1.49s\n",
      "120:\tlearn: 0.4102197\ttotal: 205ms\tremaining: 1.49s\n",
      "121:\tlearn: 0.4095414\ttotal: 206ms\tremaining: 1.48s\n",
      "122:\tlearn: 0.4086599\ttotal: 207ms\tremaining: 1.48s\n",
      "123:\tlearn: 0.4080728\ttotal: 209ms\tremaining: 1.47s\n",
      "124:\tlearn: 0.4072930\ttotal: 210ms\tremaining: 1.47s\n",
      "125:\tlearn: 0.4069069\ttotal: 211ms\tremaining: 1.46s\n",
      "126:\tlearn: 0.4065437\ttotal: 212ms\tremaining: 1.46s\n",
      "127:\tlearn: 0.4055432\ttotal: 213ms\tremaining: 1.45s\n",
      "128:\tlearn: 0.4046882\ttotal: 214ms\tremaining: 1.45s\n",
      "129:\tlearn: 0.4042792\ttotal: 215ms\tremaining: 1.44s\n",
      "130:\tlearn: 0.4030284\ttotal: 217ms\tremaining: 1.44s\n",
      "131:\tlearn: 0.4022591\ttotal: 218ms\tremaining: 1.43s\n",
      "132:\tlearn: 0.4017174\ttotal: 219ms\tremaining: 1.43s\n",
      "133:\tlearn: 0.4012757\ttotal: 220ms\tremaining: 1.42s\n",
      "134:\tlearn: 0.4002109\ttotal: 221ms\tremaining: 1.42s\n",
      "135:\tlearn: 0.3994338\ttotal: 223ms\tremaining: 1.41s\n",
      "136:\tlearn: 0.3986360\ttotal: 224ms\tremaining: 1.41s\n",
      "137:\tlearn: 0.3979837\ttotal: 225ms\tremaining: 1.41s\n",
      "138:\tlearn: 0.3972748\ttotal: 227ms\tremaining: 1.41s\n",
      "139:\tlearn: 0.3961810\ttotal: 228ms\tremaining: 1.4s\n",
      "140:\tlearn: 0.3960302\ttotal: 229ms\tremaining: 1.4s\n",
      "141:\tlearn: 0.3954065\ttotal: 230ms\tremaining: 1.39s\n",
      "142:\tlearn: 0.3947078\ttotal: 232ms\tremaining: 1.39s\n",
      "143:\tlearn: 0.3942251\ttotal: 233ms\tremaining: 1.39s\n",
      "144:\tlearn: 0.3935040\ttotal: 234ms\tremaining: 1.38s\n",
      "145:\tlearn: 0.3928558\ttotal: 236ms\tremaining: 1.38s\n",
      "146:\tlearn: 0.3923066\ttotal: 237ms\tremaining: 1.38s\n",
      "147:\tlearn: 0.3916811\ttotal: 238ms\tremaining: 1.37s\n",
      "148:\tlearn: 0.3910003\ttotal: 240ms\tremaining: 1.37s\n",
      "149:\tlearn: 0.3903902\ttotal: 241ms\tremaining: 1.37s\n",
      "150:\tlearn: 0.3897998\ttotal: 243ms\tremaining: 1.36s\n",
      "151:\tlearn: 0.3887536\ttotal: 244ms\tremaining: 1.36s\n",
      "152:\tlearn: 0.3881546\ttotal: 245ms\tremaining: 1.36s\n",
      "153:\tlearn: 0.3876575\ttotal: 247ms\tremaining: 1.35s\n",
      "154:\tlearn: 0.3868711\ttotal: 248ms\tremaining: 1.35s\n",
      "155:\tlearn: 0.3863958\ttotal: 249ms\tremaining: 1.35s\n",
      "156:\tlearn: 0.3857388\ttotal: 251ms\tremaining: 1.34s\n",
      "157:\tlearn: 0.3851474\ttotal: 252ms\tremaining: 1.34s\n",
      "158:\tlearn: 0.3844201\ttotal: 253ms\tremaining: 1.34s\n",
      "159:\tlearn: 0.3837193\ttotal: 255ms\tremaining: 1.34s\n",
      "160:\tlearn: 0.3831937\ttotal: 256ms\tremaining: 1.33s\n",
      "161:\tlearn: 0.3827339\ttotal: 257ms\tremaining: 1.33s\n",
      "162:\tlearn: 0.3823781\ttotal: 258ms\tremaining: 1.33s\n",
      "163:\tlearn: 0.3816572\ttotal: 260ms\tremaining: 1.32s\n",
      "164:\tlearn: 0.3810520\ttotal: 261ms\tremaining: 1.32s\n",
      "165:\tlearn: 0.3805142\ttotal: 262ms\tremaining: 1.32s\n",
      "166:\tlearn: 0.3796085\ttotal: 264ms\tremaining: 1.31s\n",
      "167:\tlearn: 0.3791402\ttotal: 265ms\tremaining: 1.31s\n",
      "168:\tlearn: 0.3787577\ttotal: 266ms\tremaining: 1.31s\n",
      "169:\tlearn: 0.3782519\ttotal: 267ms\tremaining: 1.3s\n",
      "170:\tlearn: 0.3776513\ttotal: 269ms\tremaining: 1.3s\n",
      "171:\tlearn: 0.3768456\ttotal: 270ms\tremaining: 1.3s\n",
      "172:\tlearn: 0.3761866\ttotal: 271ms\tremaining: 1.3s\n",
      "173:\tlearn: 0.3754204\ttotal: 273ms\tremaining: 1.29s\n",
      "174:\tlearn: 0.3748218\ttotal: 274ms\tremaining: 1.29s\n",
      "175:\tlearn: 0.3743928\ttotal: 275ms\tremaining: 1.29s\n",
      "176:\tlearn: 0.3741832\ttotal: 276ms\tremaining: 1.28s\n",
      "177:\tlearn: 0.3736466\ttotal: 277ms\tremaining: 1.28s\n",
      "178:\tlearn: 0.3731080\ttotal: 279ms\tremaining: 1.28s\n",
      "179:\tlearn: 0.3729727\ttotal: 280ms\tremaining: 1.27s\n",
      "180:\tlearn: 0.3725369\ttotal: 281ms\tremaining: 1.27s\n",
      "181:\tlearn: 0.3721269\ttotal: 282ms\tremaining: 1.27s\n",
      "182:\tlearn: 0.3712472\ttotal: 284ms\tremaining: 1.27s\n",
      "183:\tlearn: 0.3707821\ttotal: 285ms\tremaining: 1.26s\n",
      "184:\tlearn: 0.3703271\ttotal: 287ms\tremaining: 1.26s\n",
      "185:\tlearn: 0.3694976\ttotal: 288ms\tremaining: 1.26s\n",
      "186:\tlearn: 0.3690572\ttotal: 289ms\tremaining: 1.26s\n",
      "187:\tlearn: 0.3686398\ttotal: 291ms\tremaining: 1.26s\n",
      "188:\tlearn: 0.3681413\ttotal: 292ms\tremaining: 1.25s\n",
      "189:\tlearn: 0.3676785\ttotal: 293ms\tremaining: 1.25s\n",
      "190:\tlearn: 0.3670199\ttotal: 295ms\tremaining: 1.25s\n",
      "191:\tlearn: 0.3664577\ttotal: 296ms\tremaining: 1.25s\n",
      "192:\tlearn: 0.3659274\ttotal: 297ms\tremaining: 1.24s\n",
      "193:\tlearn: 0.3654349\ttotal: 299ms\tremaining: 1.24s\n",
      "194:\tlearn: 0.3650221\ttotal: 300ms\tremaining: 1.24s\n",
      "195:\tlearn: 0.3646457\ttotal: 301ms\tremaining: 1.24s\n",
      "196:\tlearn: 0.3641187\ttotal: 303ms\tremaining: 1.23s\n",
      "197:\tlearn: 0.3637071\ttotal: 304ms\tremaining: 1.23s\n",
      "198:\tlearn: 0.3632185\ttotal: 306ms\tremaining: 1.23s\n",
      "199:\tlearn: 0.3629449\ttotal: 307ms\tremaining: 1.23s\n",
      "200:\tlearn: 0.3625152\ttotal: 308ms\tremaining: 1.23s\n",
      "201:\tlearn: 0.3621024\ttotal: 310ms\tremaining: 1.22s\n",
      "202:\tlearn: 0.3617204\ttotal: 311ms\tremaining: 1.22s\n",
      "203:\tlearn: 0.3611558\ttotal: 312ms\tremaining: 1.22s\n",
      "204:\tlearn: 0.3608730\ttotal: 314ms\tremaining: 1.22s\n",
      "205:\tlearn: 0.3604456\ttotal: 315ms\tremaining: 1.21s\n",
      "206:\tlearn: 0.3601314\ttotal: 316ms\tremaining: 1.21s\n",
      "207:\tlearn: 0.3597886\ttotal: 318ms\tremaining: 1.21s\n",
      "208:\tlearn: 0.3592926\ttotal: 319ms\tremaining: 1.21s\n",
      "209:\tlearn: 0.3592001\ttotal: 320ms\tremaining: 1.2s\n",
      "210:\tlearn: 0.3588084\ttotal: 321ms\tremaining: 1.2s\n",
      "211:\tlearn: 0.3583011\ttotal: 322ms\tremaining: 1.2s\n",
      "212:\tlearn: 0.3577264\ttotal: 324ms\tremaining: 1.2s\n",
      "213:\tlearn: 0.3572744\ttotal: 325ms\tremaining: 1.19s\n",
      "214:\tlearn: 0.3569149\ttotal: 326ms\tremaining: 1.19s\n",
      "215:\tlearn: 0.3565495\ttotal: 328ms\tremaining: 1.19s\n",
      "216:\tlearn: 0.3562854\ttotal: 329ms\tremaining: 1.19s\n",
      "217:\tlearn: 0.3558300\ttotal: 330ms\tremaining: 1.18s\n",
      "218:\tlearn: 0.3555080\ttotal: 332ms\tremaining: 1.18s\n",
      "219:\tlearn: 0.3551921\ttotal: 333ms\tremaining: 1.18s\n",
      "220:\tlearn: 0.3547947\ttotal: 334ms\tremaining: 1.18s\n",
      "221:\tlearn: 0.3539852\ttotal: 336ms\tremaining: 1.18s\n",
      "222:\tlearn: 0.3536366\ttotal: 337ms\tremaining: 1.17s\n",
      "223:\tlearn: 0.3532903\ttotal: 338ms\tremaining: 1.17s\n",
      "224:\tlearn: 0.3530040\ttotal: 340ms\tremaining: 1.17s\n",
      "225:\tlearn: 0.3529052\ttotal: 340ms\tremaining: 1.16s\n",
      "226:\tlearn: 0.3527394\ttotal: 342ms\tremaining: 1.16s\n",
      "227:\tlearn: 0.3524310\ttotal: 344ms\tremaining: 1.16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228:\tlearn: 0.3522133\ttotal: 346ms\tremaining: 1.16s\n",
      "229:\tlearn: 0.3519850\ttotal: 347ms\tremaining: 1.16s\n",
      "230:\tlearn: 0.3516211\ttotal: 349ms\tremaining: 1.16s\n",
      "231:\tlearn: 0.3515177\ttotal: 350ms\tremaining: 1.16s\n",
      "232:\tlearn: 0.3511348\ttotal: 351ms\tremaining: 1.16s\n",
      "233:\tlearn: 0.3506030\ttotal: 353ms\tremaining: 1.16s\n",
      "234:\tlearn: 0.3498125\ttotal: 355ms\tremaining: 1.15s\n",
      "235:\tlearn: 0.3495629\ttotal: 356ms\tremaining: 1.15s\n",
      "236:\tlearn: 0.3492241\ttotal: 357ms\tremaining: 1.15s\n",
      "237:\tlearn: 0.3489128\ttotal: 359ms\tremaining: 1.15s\n",
      "238:\tlearn: 0.3483965\ttotal: 360ms\tremaining: 1.15s\n",
      "239:\tlearn: 0.3477435\ttotal: 362ms\tremaining: 1.15s\n",
      "240:\tlearn: 0.3472320\ttotal: 363ms\tremaining: 1.14s\n",
      "241:\tlearn: 0.3466172\ttotal: 365ms\tremaining: 1.14s\n",
      "242:\tlearn: 0.3463245\ttotal: 366ms\tremaining: 1.14s\n",
      "243:\tlearn: 0.3461322\ttotal: 367ms\tremaining: 1.14s\n",
      "244:\tlearn: 0.3458674\ttotal: 369ms\tremaining: 1.14s\n",
      "245:\tlearn: 0.3454650\ttotal: 370ms\tremaining: 1.13s\n",
      "246:\tlearn: 0.3450718\ttotal: 372ms\tremaining: 1.13s\n",
      "247:\tlearn: 0.3448569\ttotal: 373ms\tremaining: 1.13s\n",
      "248:\tlearn: 0.3445809\ttotal: 375ms\tremaining: 1.13s\n",
      "249:\tlearn: 0.3442453\ttotal: 376ms\tremaining: 1.13s\n",
      "250:\tlearn: 0.3440373\ttotal: 378ms\tremaining: 1.13s\n",
      "251:\tlearn: 0.3436048\ttotal: 380ms\tremaining: 1.13s\n",
      "252:\tlearn: 0.3431379\ttotal: 382ms\tremaining: 1.13s\n",
      "253:\tlearn: 0.3425075\ttotal: 383ms\tremaining: 1.13s\n",
      "254:\tlearn: 0.3419805\ttotal: 385ms\tremaining: 1.13s\n",
      "255:\tlearn: 0.3416797\ttotal: 387ms\tremaining: 1.12s\n",
      "256:\tlearn: 0.3414645\ttotal: 388ms\tremaining: 1.12s\n",
      "257:\tlearn: 0.3412014\ttotal: 390ms\tremaining: 1.12s\n",
      "258:\tlearn: 0.3409457\ttotal: 391ms\tremaining: 1.12s\n",
      "259:\tlearn: 0.3404412\ttotal: 393ms\tremaining: 1.12s\n",
      "260:\tlearn: 0.3401800\ttotal: 394ms\tremaining: 1.11s\n",
      "261:\tlearn: 0.3397755\ttotal: 395ms\tremaining: 1.11s\n",
      "262:\tlearn: 0.3394117\ttotal: 397ms\tremaining: 1.11s\n",
      "263:\tlearn: 0.3391516\ttotal: 399ms\tremaining: 1.11s\n",
      "264:\tlearn: 0.3387205\ttotal: 400ms\tremaining: 1.11s\n",
      "265:\tlearn: 0.3383963\ttotal: 401ms\tremaining: 1.11s\n",
      "266:\tlearn: 0.3381657\ttotal: 403ms\tremaining: 1.11s\n",
      "267:\tlearn: 0.3380862\ttotal: 404ms\tremaining: 1.1s\n",
      "268:\tlearn: 0.3378060\ttotal: 405ms\tremaining: 1.1s\n",
      "269:\tlearn: 0.3375384\ttotal: 407ms\tremaining: 1.1s\n",
      "270:\tlearn: 0.3372956\ttotal: 408ms\tremaining: 1.1s\n",
      "271:\tlearn: 0.3370982\ttotal: 410ms\tremaining: 1.1s\n",
      "272:\tlearn: 0.3364609\ttotal: 411ms\tremaining: 1.09s\n",
      "273:\tlearn: 0.3361166\ttotal: 413ms\tremaining: 1.09s\n",
      "274:\tlearn: 0.3358239\ttotal: 415ms\tremaining: 1.09s\n",
      "275:\tlearn: 0.3356089\ttotal: 417ms\tremaining: 1.09s\n",
      "276:\tlearn: 0.3353098\ttotal: 418ms\tremaining: 1.09s\n",
      "277:\tlearn: 0.3350393\ttotal: 420ms\tremaining: 1.09s\n",
      "278:\tlearn: 0.3347557\ttotal: 421ms\tremaining: 1.09s\n",
      "279:\tlearn: 0.3343473\ttotal: 423ms\tremaining: 1.09s\n",
      "280:\tlearn: 0.3342522\ttotal: 424ms\tremaining: 1.08s\n",
      "281:\tlearn: 0.3339191\ttotal: 425ms\tremaining: 1.08s\n",
      "282:\tlearn: 0.3336790\ttotal: 426ms\tremaining: 1.08s\n",
      "283:\tlearn: 0.3334074\ttotal: 428ms\tremaining: 1.08s\n",
      "284:\tlearn: 0.3331292\ttotal: 429ms\tremaining: 1.08s\n",
      "285:\tlearn: 0.3328289\ttotal: 431ms\tremaining: 1.07s\n",
      "286:\tlearn: 0.3326798\ttotal: 432ms\tremaining: 1.07s\n",
      "287:\tlearn: 0.3324703\ttotal: 434ms\tremaining: 1.07s\n",
      "288:\tlearn: 0.3323956\ttotal: 434ms\tremaining: 1.07s\n",
      "289:\tlearn: 0.3319714\ttotal: 436ms\tremaining: 1.07s\n",
      "290:\tlearn: 0.3317162\ttotal: 437ms\tremaining: 1.06s\n",
      "291:\tlearn: 0.3315323\ttotal: 439ms\tremaining: 1.06s\n",
      "292:\tlearn: 0.3313171\ttotal: 440ms\tremaining: 1.06s\n",
      "293:\tlearn: 0.3310231\ttotal: 441ms\tremaining: 1.06s\n",
      "294:\tlearn: 0.3307186\ttotal: 443ms\tremaining: 1.06s\n",
      "295:\tlearn: 0.3304329\ttotal: 444ms\tremaining: 1.05s\n",
      "296:\tlearn: 0.3302269\ttotal: 445ms\tremaining: 1.05s\n",
      "297:\tlearn: 0.3301733\ttotal: 446ms\tremaining: 1.05s\n",
      "298:\tlearn: 0.3299275\ttotal: 448ms\tremaining: 1.05s\n",
      "299:\tlearn: 0.3297523\ttotal: 449ms\tremaining: 1.05s\n",
      "300:\tlearn: 0.3292870\ttotal: 450ms\tremaining: 1.04s\n",
      "301:\tlearn: 0.3290524\ttotal: 452ms\tremaining: 1.04s\n",
      "302:\tlearn: 0.3288739\ttotal: 453ms\tremaining: 1.04s\n",
      "303:\tlearn: 0.3280690\ttotal: 454ms\tremaining: 1.04s\n",
      "304:\tlearn: 0.3275954\ttotal: 456ms\tremaining: 1.04s\n",
      "305:\tlearn: 0.3272866\ttotal: 457ms\tremaining: 1.04s\n",
      "306:\tlearn: 0.3268947\ttotal: 459ms\tremaining: 1.03s\n",
      "307:\tlearn: 0.3267141\ttotal: 460ms\tremaining: 1.03s\n",
      "308:\tlearn: 0.3263607\ttotal: 461ms\tremaining: 1.03s\n",
      "309:\tlearn: 0.3260324\ttotal: 463ms\tremaining: 1.03s\n",
      "310:\tlearn: 0.3256306\ttotal: 464ms\tremaining: 1.03s\n",
      "311:\tlearn: 0.3251874\ttotal: 465ms\tremaining: 1.03s\n",
      "312:\tlearn: 0.3250015\ttotal: 467ms\tremaining: 1.02s\n",
      "313:\tlearn: 0.3247558\ttotal: 468ms\tremaining: 1.02s\n",
      "314:\tlearn: 0.3245578\ttotal: 469ms\tremaining: 1.02s\n",
      "315:\tlearn: 0.3243893\ttotal: 471ms\tremaining: 1.02s\n",
      "316:\tlearn: 0.3241954\ttotal: 472ms\tremaining: 1.02s\n",
      "317:\tlearn: 0.3238583\ttotal: 473ms\tremaining: 1.01s\n",
      "318:\tlearn: 0.3237235\ttotal: 475ms\tremaining: 1.01s\n",
      "319:\tlearn: 0.3235255\ttotal: 476ms\tremaining: 1.01s\n",
      "320:\tlearn: 0.3233202\ttotal: 477ms\tremaining: 1.01s\n",
      "321:\tlearn: 0.3231455\ttotal: 479ms\tremaining: 1.01s\n",
      "322:\tlearn: 0.3229344\ttotal: 480ms\tremaining: 1.01s\n",
      "323:\tlearn: 0.3227418\ttotal: 481ms\tremaining: 1s\n",
      "324:\tlearn: 0.3225877\ttotal: 483ms\tremaining: 1s\n",
      "325:\tlearn: 0.3223130\ttotal: 484ms\tremaining: 1s\n",
      "326:\tlearn: 0.3221488\ttotal: 485ms\tremaining: 999ms\n",
      "327:\tlearn: 0.3219856\ttotal: 487ms\tremaining: 997ms\n",
      "328:\tlearn: 0.3213552\ttotal: 488ms\tremaining: 996ms\n",
      "329:\tlearn: 0.3211838\ttotal: 489ms\tremaining: 994ms\n",
      "330:\tlearn: 0.3209128\ttotal: 491ms\tremaining: 992ms\n",
      "331:\tlearn: 0.3206486\ttotal: 492ms\tremaining: 990ms\n",
      "332:\tlearn: 0.3205119\ttotal: 494ms\tremaining: 988ms\n",
      "333:\tlearn: 0.3203480\ttotal: 495ms\tremaining: 987ms\n",
      "334:\tlearn: 0.3201420\ttotal: 496ms\tremaining: 985ms\n",
      "335:\tlearn: 0.3197345\ttotal: 498ms\tremaining: 983ms\n",
      "336:\tlearn: 0.3194934\ttotal: 499ms\tremaining: 981ms\n",
      "337:\tlearn: 0.3192712\ttotal: 500ms\tremaining: 980ms\n",
      "338:\tlearn: 0.3188335\ttotal: 502ms\tremaining: 978ms\n",
      "339:\tlearn: 0.3185512\ttotal: 503ms\tremaining: 977ms\n",
      "340:\tlearn: 0.3184650\ttotal: 504ms\tremaining: 974ms\n",
      "341:\tlearn: 0.3180749\ttotal: 505ms\tremaining: 973ms\n",
      "342:\tlearn: 0.3179366\ttotal: 507ms\tremaining: 971ms\n",
      "343:\tlearn: 0.3177519\ttotal: 508ms\tremaining: 969ms\n",
      "344:\tlearn: 0.3175832\ttotal: 510ms\tremaining: 967ms\n",
      "345:\tlearn: 0.3174230\ttotal: 511ms\tremaining: 966ms\n",
      "346:\tlearn: 0.3173304\ttotal: 512ms\tremaining: 964ms\n",
      "347:\tlearn: 0.3168776\ttotal: 514ms\tremaining: 962ms\n",
      "348:\tlearn: 0.3166779\ttotal: 515ms\tremaining: 961ms\n",
      "349:\tlearn: 0.3165732\ttotal: 516ms\tremaining: 959ms\n",
      "350:\tlearn: 0.3165531\ttotal: 517ms\tremaining: 956ms\n",
      "351:\tlearn: 0.3165222\ttotal: 518ms\tremaining: 954ms\n",
      "352:\tlearn: 0.3162815\ttotal: 519ms\tremaining: 952ms\n",
      "353:\tlearn: 0.3160546\ttotal: 521ms\tremaining: 951ms\n",
      "354:\tlearn: 0.3158937\ttotal: 523ms\tremaining: 950ms\n",
      "355:\tlearn: 0.3155325\ttotal: 524ms\tremaining: 948ms\n",
      "356:\tlearn: 0.3154855\ttotal: 525ms\tremaining: 945ms\n",
      "357:\tlearn: 0.3153400\ttotal: 526ms\tremaining: 944ms\n",
      "358:\tlearn: 0.3152313\ttotal: 528ms\tremaining: 942ms\n",
      "359:\tlearn: 0.3151260\ttotal: 529ms\tremaining: 941ms\n",
      "360:\tlearn: 0.3149636\ttotal: 531ms\tremaining: 939ms\n",
      "361:\tlearn: 0.3147129\ttotal: 532ms\tremaining: 938ms\n",
      "362:\tlearn: 0.3141637\ttotal: 534ms\tremaining: 937ms\n",
      "363:\tlearn: 0.3139775\ttotal: 535ms\tremaining: 935ms\n",
      "364:\tlearn: 0.3136071\ttotal: 537ms\tremaining: 933ms\n",
      "365:\tlearn: 0.3133551\ttotal: 538ms\tremaining: 932ms\n",
      "366:\tlearn: 0.3131281\ttotal: 540ms\tremaining: 931ms\n",
      "367:\tlearn: 0.3130894\ttotal: 541ms\tremaining: 929ms\n",
      "368:\tlearn: 0.3127531\ttotal: 543ms\tremaining: 928ms\n",
      "369:\tlearn: 0.3125665\ttotal: 544ms\tremaining: 926ms\n",
      "370:\tlearn: 0.3123352\ttotal: 546ms\tremaining: 925ms\n",
      "371:\tlearn: 0.3121631\ttotal: 547ms\tremaining: 924ms\n",
      "372:\tlearn: 0.3119265\ttotal: 549ms\tremaining: 922ms\n",
      "373:\tlearn: 0.3117781\ttotal: 550ms\tremaining: 920ms\n",
      "374:\tlearn: 0.3115510\ttotal: 551ms\tremaining: 919ms\n",
      "375:\tlearn: 0.3113572\ttotal: 553ms\tremaining: 917ms\n",
      "376:\tlearn: 0.3111967\ttotal: 554ms\tremaining: 915ms\n",
      "377:\tlearn: 0.3109170\ttotal: 556ms\tremaining: 914ms\n",
      "378:\tlearn: 0.3106177\ttotal: 557ms\tremaining: 912ms\n",
      "379:\tlearn: 0.3104046\ttotal: 558ms\tremaining: 911ms\n",
      "380:\tlearn: 0.3100460\ttotal: 560ms\tremaining: 909ms\n",
      "381:\tlearn: 0.3098393\ttotal: 561ms\tremaining: 908ms\n",
      "382:\tlearn: 0.3093727\ttotal: 562ms\tremaining: 906ms\n",
      "383:\tlearn: 0.3090855\ttotal: 564ms\tremaining: 904ms\n",
      "384:\tlearn: 0.3088550\ttotal: 565ms\tremaining: 903ms\n",
      "385:\tlearn: 0.3086743\ttotal: 567ms\tremaining: 901ms\n",
      "386:\tlearn: 0.3086340\ttotal: 567ms\tremaining: 899ms\n",
      "387:\tlearn: 0.3084954\ttotal: 569ms\tremaining: 897ms\n",
      "388:\tlearn: 0.3082675\ttotal: 570ms\tremaining: 896ms\n",
      "389:\tlearn: 0.3079539\ttotal: 571ms\tremaining: 894ms\n",
      "390:\tlearn: 0.3078664\ttotal: 573ms\tremaining: 892ms\n",
      "391:\tlearn: 0.3075216\ttotal: 574ms\tremaining: 891ms\n",
      "392:\tlearn: 0.3072510\ttotal: 576ms\tremaining: 889ms\n",
      "393:\tlearn: 0.3071767\ttotal: 576ms\tremaining: 887ms\n",
      "394:\tlearn: 0.3069070\ttotal: 578ms\tremaining: 885ms\n",
      "395:\tlearn: 0.3067821\ttotal: 579ms\tremaining: 883ms\n",
      "396:\tlearn: 0.3066233\ttotal: 581ms\tremaining: 882ms\n",
      "397:\tlearn: 0.3064536\ttotal: 582ms\tremaining: 880ms\n",
      "398:\tlearn: 0.3063520\ttotal: 583ms\tremaining: 878ms\n",
      "399:\tlearn: 0.3061040\ttotal: 584ms\tremaining: 876ms\n",
      "400:\tlearn: 0.3058594\ttotal: 586ms\tremaining: 875ms\n",
      "401:\tlearn: 0.3055769\ttotal: 587ms\tremaining: 873ms\n",
      "402:\tlearn: 0.3054198\ttotal: 588ms\tremaining: 872ms\n",
      "403:\tlearn: 0.3052026\ttotal: 590ms\tremaining: 870ms\n",
      "404:\tlearn: 0.3051155\ttotal: 591ms\tremaining: 868ms\n",
      "405:\tlearn: 0.3050097\ttotal: 592ms\tremaining: 866ms\n",
      "406:\tlearn: 0.3046498\ttotal: 593ms\tremaining: 864ms\n",
      "407:\tlearn: 0.3045615\ttotal: 595ms\tremaining: 863ms\n",
      "408:\tlearn: 0.3045380\ttotal: 595ms\tremaining: 860ms\n",
      "409:\tlearn: 0.3042050\ttotal: 597ms\tremaining: 859ms\n",
      "410:\tlearn: 0.3040655\ttotal: 598ms\tremaining: 857ms\n",
      "411:\tlearn: 0.3036678\ttotal: 599ms\tremaining: 855ms\n",
      "412:\tlearn: 0.3034439\ttotal: 601ms\tremaining: 854ms\n",
      "413:\tlearn: 0.3034210\ttotal: 601ms\tremaining: 851ms\n",
      "414:\tlearn: 0.3032811\ttotal: 603ms\tremaining: 850ms\n",
      "415:\tlearn: 0.3031561\ttotal: 604ms\tremaining: 848ms\n",
      "416:\tlearn: 0.3030786\ttotal: 605ms\tremaining: 846ms\n",
      "417:\tlearn: 0.3029184\ttotal: 606ms\tremaining: 844ms\n",
      "418:\tlearn: 0.3026622\ttotal: 608ms\tremaining: 843ms\n",
      "419:\tlearn: 0.3023790\ttotal: 609ms\tremaining: 841ms\n",
      "420:\tlearn: 0.3020050\ttotal: 610ms\tremaining: 839ms\n",
      "421:\tlearn: 0.3017944\ttotal: 612ms\tremaining: 838ms\n",
      "422:\tlearn: 0.3016495\ttotal: 613ms\tremaining: 836ms\n",
      "423:\tlearn: 0.3016262\ttotal: 614ms\tremaining: 834ms\n",
      "424:\tlearn: 0.3015076\ttotal: 615ms\tremaining: 832ms\n",
      "425:\tlearn: 0.3013036\ttotal: 616ms\tremaining: 830ms\n",
      "426:\tlearn: 0.3010194\ttotal: 618ms\tremaining: 829ms\n",
      "427:\tlearn: 0.3007956\ttotal: 619ms\tremaining: 827ms\n",
      "428:\tlearn: 0.3005628\ttotal: 620ms\tremaining: 826ms\n",
      "429:\tlearn: 0.3005097\ttotal: 621ms\tremaining: 824ms\n",
      "430:\tlearn: 0.3004456\ttotal: 623ms\tremaining: 822ms\n",
      "431:\tlearn: 0.3001085\ttotal: 624ms\tremaining: 821ms\n",
      "432:\tlearn: 0.2998734\ttotal: 625ms\tremaining: 819ms\n",
      "433:\tlearn: 0.2994173\ttotal: 627ms\tremaining: 817ms\n",
      "434:\tlearn: 0.2992828\ttotal: 628ms\tremaining: 816ms\n",
      "435:\tlearn: 0.2991837\ttotal: 629ms\tremaining: 814ms\n",
      "436:\tlearn: 0.2990275\ttotal: 631ms\tremaining: 813ms\n",
      "437:\tlearn: 0.2989541\ttotal: 632ms\tremaining: 811ms\n",
      "438:\tlearn: 0.2988563\ttotal: 633ms\tremaining: 810ms\n",
      "439:\tlearn: 0.2982966\ttotal: 635ms\tremaining: 808ms\n",
      "440:\tlearn: 0.2982243\ttotal: 636ms\tremaining: 806ms\n",
      "441:\tlearn: 0.2979386\ttotal: 637ms\tremaining: 804ms\n",
      "442:\tlearn: 0.2977493\ttotal: 639ms\tremaining: 803ms\n",
      "443:\tlearn: 0.2975983\ttotal: 640ms\tremaining: 801ms\n",
      "444:\tlearn: 0.2974402\ttotal: 641ms\tremaining: 800ms\n",
      "445:\tlearn: 0.2972749\ttotal: 643ms\tremaining: 798ms\n",
      "446:\tlearn: 0.2970367\ttotal: 644ms\tremaining: 797ms\n",
      "447:\tlearn: 0.2969237\ttotal: 645ms\tremaining: 795ms\n",
      "448:\tlearn: 0.2967262\ttotal: 646ms\tremaining: 793ms\n",
      "449:\tlearn: 0.2965155\ttotal: 648ms\tremaining: 792ms\n",
      "450:\tlearn: 0.2961882\ttotal: 649ms\tremaining: 790ms\n",
      "451:\tlearn: 0.2959657\ttotal: 650ms\tremaining: 789ms\n",
      "452:\tlearn: 0.2958310\ttotal: 652ms\tremaining: 787ms\n",
      "453:\tlearn: 0.2955130\ttotal: 653ms\tremaining: 785ms\n",
      "454:\tlearn: 0.2953726\ttotal: 654ms\tremaining: 784ms\n",
      "455:\tlearn: 0.2952770\ttotal: 656ms\tremaining: 782ms\n",
      "456:\tlearn: 0.2951209\ttotal: 657ms\tremaining: 781ms\n",
      "457:\tlearn: 0.2950409\ttotal: 659ms\tremaining: 779ms\n",
      "458:\tlearn: 0.2948498\ttotal: 660ms\tremaining: 778ms\n",
      "459:\tlearn: 0.2945156\ttotal: 661ms\tremaining: 776ms\n",
      "460:\tlearn: 0.2943026\ttotal: 663ms\tremaining: 775ms\n",
      "461:\tlearn: 0.2942625\ttotal: 663ms\tremaining: 773ms\n",
      "462:\tlearn: 0.2940156\ttotal: 665ms\tremaining: 771ms\n",
      "463:\tlearn: 0.2938256\ttotal: 666ms\tremaining: 769ms\n",
      "464:\tlearn: 0.2936911\ttotal: 667ms\tremaining: 768ms\n",
      "465:\tlearn: 0.2935816\ttotal: 669ms\tremaining: 766ms\n",
      "466:\tlearn: 0.2933150\ttotal: 670ms\tremaining: 765ms\n",
      "467:\tlearn: 0.2931809\ttotal: 671ms\tremaining: 763ms\n",
      "468:\tlearn: 0.2929717\ttotal: 673ms\tremaining: 762ms\n",
      "469:\tlearn: 0.2927897\ttotal: 674ms\tremaining: 760ms\n",
      "470:\tlearn: 0.2926225\ttotal: 675ms\tremaining: 759ms\n",
      "471:\tlearn: 0.2923908\ttotal: 677ms\tremaining: 757ms\n",
      "472:\tlearn: 0.2922514\ttotal: 678ms\tremaining: 755ms\n",
      "473:\tlearn: 0.2920332\ttotal: 679ms\tremaining: 754ms\n",
      "474:\tlearn: 0.2919302\ttotal: 681ms\tremaining: 752ms\n",
      "475:\tlearn: 0.2917568\ttotal: 682ms\tremaining: 751ms\n",
      "476:\tlearn: 0.2915883\ttotal: 683ms\tremaining: 749ms\n",
      "477:\tlearn: 0.2914958\ttotal: 685ms\tremaining: 748ms\n",
      "478:\tlearn: 0.2913406\ttotal: 686ms\tremaining: 746ms\n",
      "479:\tlearn: 0.2911347\ttotal: 687ms\tremaining: 745ms\n",
      "480:\tlearn: 0.2909791\ttotal: 689ms\tremaining: 743ms\n",
      "481:\tlearn: 0.2907621\ttotal: 690ms\tremaining: 742ms\n",
      "482:\tlearn: 0.2905892\ttotal: 691ms\tremaining: 740ms\n",
      "483:\tlearn: 0.2901614\ttotal: 692ms\tremaining: 738ms\n",
      "484:\tlearn: 0.2900617\ttotal: 694ms\tremaining: 737ms\n",
      "485:\tlearn: 0.2899984\ttotal: 695ms\tremaining: 735ms\n",
      "486:\tlearn: 0.2898772\ttotal: 696ms\tremaining: 733ms\n",
      "487:\tlearn: 0.2898183\ttotal: 697ms\tremaining: 732ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488:\tlearn: 0.2896936\ttotal: 699ms\tremaining: 730ms\n",
      "489:\tlearn: 0.2895863\ttotal: 701ms\tremaining: 729ms\n",
      "490:\tlearn: 0.2894823\ttotal: 702ms\tremaining: 728ms\n",
      "491:\tlearn: 0.2892993\ttotal: 704ms\tremaining: 726ms\n",
      "492:\tlearn: 0.2890380\ttotal: 705ms\tremaining: 725ms\n",
      "493:\tlearn: 0.2887983\ttotal: 706ms\tremaining: 724ms\n",
      "494:\tlearn: 0.2887460\ttotal: 708ms\tremaining: 722ms\n",
      "495:\tlearn: 0.2884553\ttotal: 709ms\tremaining: 721ms\n",
      "496:\tlearn: 0.2883686\ttotal: 711ms\tremaining: 719ms\n",
      "497:\tlearn: 0.2881668\ttotal: 712ms\tremaining: 718ms\n",
      "498:\tlearn: 0.2880520\ttotal: 714ms\tremaining: 716ms\n",
      "499:\tlearn: 0.2878227\ttotal: 715ms\tremaining: 715ms\n",
      "500:\tlearn: 0.2877667\ttotal: 716ms\tremaining: 713ms\n",
      "501:\tlearn: 0.2877500\ttotal: 717ms\tremaining: 712ms\n",
      "502:\tlearn: 0.2875400\ttotal: 719ms\tremaining: 710ms\n",
      "503:\tlearn: 0.2873172\ttotal: 721ms\tremaining: 709ms\n",
      "504:\tlearn: 0.2870671\ttotal: 722ms\tremaining: 708ms\n",
      "505:\tlearn: 0.2867285\ttotal: 724ms\tremaining: 706ms\n",
      "506:\tlearn: 0.2863838\ttotal: 725ms\tremaining: 705ms\n",
      "507:\tlearn: 0.2860864\ttotal: 726ms\tremaining: 703ms\n",
      "508:\tlearn: 0.2857214\ttotal: 728ms\tremaining: 702ms\n",
      "509:\tlearn: 0.2855653\ttotal: 729ms\tremaining: 701ms\n",
      "510:\tlearn: 0.2853665\ttotal: 731ms\tremaining: 699ms\n",
      "511:\tlearn: 0.2850722\ttotal: 732ms\tremaining: 698ms\n",
      "512:\tlearn: 0.2848337\ttotal: 733ms\tremaining: 696ms\n",
      "513:\tlearn: 0.2847596\ttotal: 734ms\tremaining: 694ms\n",
      "514:\tlearn: 0.2845679\ttotal: 736ms\tremaining: 693ms\n",
      "515:\tlearn: 0.2844844\ttotal: 737ms\tremaining: 691ms\n",
      "516:\tlearn: 0.2842909\ttotal: 738ms\tremaining: 690ms\n",
      "517:\tlearn: 0.2840769\ttotal: 740ms\tremaining: 688ms\n",
      "518:\tlearn: 0.2839406\ttotal: 741ms\tremaining: 687ms\n",
      "519:\tlearn: 0.2838809\ttotal: 742ms\tremaining: 685ms\n",
      "520:\tlearn: 0.2837843\ttotal: 744ms\tremaining: 684ms\n",
      "521:\tlearn: 0.2836597\ttotal: 745ms\tremaining: 682ms\n",
      "522:\tlearn: 0.2835211\ttotal: 746ms\tremaining: 681ms\n",
      "523:\tlearn: 0.2834601\ttotal: 748ms\tremaining: 679ms\n",
      "524:\tlearn: 0.2832634\ttotal: 749ms\tremaining: 678ms\n",
      "525:\tlearn: 0.2831313\ttotal: 750ms\tremaining: 676ms\n",
      "526:\tlearn: 0.2829536\ttotal: 752ms\tremaining: 675ms\n",
      "527:\tlearn: 0.2827274\ttotal: 753ms\tremaining: 673ms\n",
      "528:\tlearn: 0.2826441\ttotal: 754ms\tremaining: 672ms\n",
      "529:\tlearn: 0.2824521\ttotal: 756ms\tremaining: 670ms\n",
      "530:\tlearn: 0.2823413\ttotal: 757ms\tremaining: 669ms\n",
      "531:\tlearn: 0.2821061\ttotal: 758ms\tremaining: 667ms\n",
      "532:\tlearn: 0.2819846\ttotal: 760ms\tremaining: 666ms\n",
      "533:\tlearn: 0.2818490\ttotal: 761ms\tremaining: 664ms\n",
      "534:\tlearn: 0.2817674\ttotal: 762ms\tremaining: 662ms\n",
      "535:\tlearn: 0.2816421\ttotal: 763ms\tremaining: 661ms\n",
      "536:\tlearn: 0.2815985\ttotal: 765ms\tremaining: 659ms\n",
      "537:\tlearn: 0.2813756\ttotal: 766ms\tremaining: 658ms\n",
      "538:\tlearn: 0.2811965\ttotal: 767ms\tremaining: 656ms\n",
      "539:\tlearn: 0.2810710\ttotal: 769ms\tremaining: 655ms\n",
      "540:\tlearn: 0.2809437\ttotal: 770ms\tremaining: 653ms\n",
      "541:\tlearn: 0.2806840\ttotal: 771ms\tremaining: 652ms\n",
      "542:\tlearn: 0.2804521\ttotal: 773ms\tremaining: 650ms\n",
      "543:\tlearn: 0.2803044\ttotal: 774ms\tremaining: 649ms\n",
      "544:\tlearn: 0.2800503\ttotal: 775ms\tremaining: 647ms\n",
      "545:\tlearn: 0.2798877\ttotal: 777ms\tremaining: 646ms\n",
      "546:\tlearn: 0.2796683\ttotal: 778ms\tremaining: 644ms\n",
      "547:\tlearn: 0.2795864\ttotal: 779ms\tremaining: 643ms\n",
      "548:\tlearn: 0.2794857\ttotal: 781ms\tremaining: 641ms\n",
      "549:\tlearn: 0.2792443\ttotal: 782ms\tremaining: 640ms\n",
      "550:\tlearn: 0.2792315\ttotal: 783ms\tremaining: 638ms\n",
      "551:\tlearn: 0.2792214\ttotal: 783ms\tremaining: 636ms\n",
      "552:\tlearn: 0.2790567\ttotal: 785ms\tremaining: 634ms\n",
      "553:\tlearn: 0.2790025\ttotal: 786ms\tremaining: 633ms\n",
      "554:\tlearn: 0.2789445\ttotal: 787ms\tremaining: 631ms\n",
      "555:\tlearn: 0.2788227\ttotal: 789ms\tremaining: 630ms\n",
      "556:\tlearn: 0.2787001\ttotal: 790ms\tremaining: 628ms\n",
      "557:\tlearn: 0.2785805\ttotal: 791ms\tremaining: 627ms\n",
      "558:\tlearn: 0.2785273\ttotal: 792ms\tremaining: 625ms\n",
      "559:\tlearn: 0.2784365\ttotal: 794ms\tremaining: 624ms\n",
      "560:\tlearn: 0.2784204\ttotal: 795ms\tremaining: 622ms\n",
      "561:\tlearn: 0.2782567\ttotal: 796ms\tremaining: 620ms\n",
      "562:\tlearn: 0.2780853\ttotal: 797ms\tremaining: 619ms\n",
      "563:\tlearn: 0.2780663\ttotal: 798ms\tremaining: 617ms\n",
      "564:\tlearn: 0.2779683\ttotal: 800ms\tremaining: 616ms\n",
      "565:\tlearn: 0.2778384\ttotal: 801ms\tremaining: 614ms\n",
      "566:\tlearn: 0.2776612\ttotal: 803ms\tremaining: 613ms\n",
      "567:\tlearn: 0.2775217\ttotal: 804ms\tremaining: 611ms\n",
      "568:\tlearn: 0.2773723\ttotal: 805ms\tremaining: 610ms\n",
      "569:\tlearn: 0.2772966\ttotal: 807ms\tremaining: 609ms\n",
      "570:\tlearn: 0.2770661\ttotal: 808ms\tremaining: 607ms\n",
      "571:\tlearn: 0.2770083\ttotal: 809ms\tremaining: 606ms\n",
      "572:\tlearn: 0.2769913\ttotal: 810ms\tremaining: 604ms\n",
      "573:\tlearn: 0.2769218\ttotal: 811ms\tremaining: 602ms\n",
      "574:\tlearn: 0.2768362\ttotal: 813ms\tremaining: 601ms\n",
      "575:\tlearn: 0.2767356\ttotal: 814ms\tremaining: 599ms\n",
      "576:\tlearn: 0.2766234\ttotal: 815ms\tremaining: 598ms\n",
      "577:\tlearn: 0.2764752\ttotal: 817ms\tremaining: 596ms\n",
      "578:\tlearn: 0.2764374\ttotal: 818ms\tremaining: 595ms\n",
      "579:\tlearn: 0.2763268\ttotal: 819ms\tremaining: 593ms\n",
      "580:\tlearn: 0.2762408\ttotal: 820ms\tremaining: 592ms\n",
      "581:\tlearn: 0.2762006\ttotal: 822ms\tremaining: 590ms\n",
      "582:\tlearn: 0.2760072\ttotal: 823ms\tremaining: 589ms\n",
      "583:\tlearn: 0.2758202\ttotal: 824ms\tremaining: 587ms\n",
      "584:\tlearn: 0.2755953\ttotal: 826ms\tremaining: 586ms\n",
      "585:\tlearn: 0.2754452\ttotal: 827ms\tremaining: 584ms\n",
      "586:\tlearn: 0.2753006\ttotal: 828ms\tremaining: 583ms\n",
      "587:\tlearn: 0.2752140\ttotal: 830ms\tremaining: 581ms\n",
      "588:\tlearn: 0.2751453\ttotal: 831ms\tremaining: 580ms\n",
      "589:\tlearn: 0.2749962\ttotal: 832ms\tremaining: 578ms\n",
      "590:\tlearn: 0.2748666\ttotal: 834ms\tremaining: 577ms\n",
      "591:\tlearn: 0.2746208\ttotal: 835ms\tremaining: 575ms\n",
      "592:\tlearn: 0.2744352\ttotal: 836ms\tremaining: 574ms\n",
      "593:\tlearn: 0.2743718\ttotal: 838ms\tremaining: 573ms\n",
      "594:\tlearn: 0.2741737\ttotal: 839ms\tremaining: 571ms\n",
      "595:\tlearn: 0.2740441\ttotal: 840ms\tremaining: 570ms\n",
      "596:\tlearn: 0.2737274\ttotal: 842ms\tremaining: 568ms\n",
      "597:\tlearn: 0.2735421\ttotal: 843ms\tremaining: 567ms\n",
      "598:\tlearn: 0.2734449\ttotal: 844ms\tremaining: 565ms\n",
      "599:\tlearn: 0.2733320\ttotal: 846ms\tremaining: 564ms\n",
      "600:\tlearn: 0.2731430\ttotal: 847ms\tremaining: 563ms\n",
      "601:\tlearn: 0.2729712\ttotal: 849ms\tremaining: 561ms\n",
      "602:\tlearn: 0.2726639\ttotal: 850ms\tremaining: 560ms\n",
      "603:\tlearn: 0.2725231\ttotal: 852ms\tremaining: 558ms\n",
      "604:\tlearn: 0.2723985\ttotal: 853ms\tremaining: 557ms\n",
      "605:\tlearn: 0.2722850\ttotal: 854ms\tremaining: 556ms\n",
      "606:\tlearn: 0.2721746\ttotal: 856ms\tremaining: 554ms\n",
      "607:\tlearn: 0.2720500\ttotal: 857ms\tremaining: 553ms\n",
      "608:\tlearn: 0.2718945\ttotal: 858ms\tremaining: 551ms\n",
      "609:\tlearn: 0.2717078\ttotal: 860ms\tremaining: 550ms\n",
      "610:\tlearn: 0.2716079\ttotal: 861ms\tremaining: 548ms\n",
      "611:\tlearn: 0.2714123\ttotal: 862ms\tremaining: 547ms\n",
      "612:\tlearn: 0.2713526\ttotal: 864ms\tremaining: 545ms\n",
      "613:\tlearn: 0.2710378\ttotal: 865ms\tremaining: 544ms\n",
      "614:\tlearn: 0.2708998\ttotal: 866ms\tremaining: 542ms\n",
      "615:\tlearn: 0.2708898\ttotal: 867ms\tremaining: 540ms\n",
      "616:\tlearn: 0.2705990\ttotal: 868ms\tremaining: 539ms\n",
      "617:\tlearn: 0.2703929\ttotal: 870ms\tremaining: 538ms\n",
      "618:\tlearn: 0.2701975\ttotal: 871ms\tremaining: 536ms\n",
      "619:\tlearn: 0.2700333\ttotal: 872ms\tremaining: 535ms\n",
      "620:\tlearn: 0.2698951\ttotal: 874ms\tremaining: 533ms\n",
      "621:\tlearn: 0.2695257\ttotal: 875ms\tremaining: 532ms\n",
      "622:\tlearn: 0.2694097\ttotal: 877ms\tremaining: 530ms\n",
      "623:\tlearn: 0.2693106\ttotal: 878ms\tremaining: 529ms\n",
      "624:\tlearn: 0.2690934\ttotal: 880ms\tremaining: 528ms\n",
      "625:\tlearn: 0.2689997\ttotal: 881ms\tremaining: 526ms\n",
      "626:\tlearn: 0.2687845\ttotal: 883ms\tremaining: 525ms\n",
      "627:\tlearn: 0.2686497\ttotal: 884ms\tremaining: 524ms\n",
      "628:\tlearn: 0.2685887\ttotal: 886ms\tremaining: 522ms\n",
      "629:\tlearn: 0.2684520\ttotal: 887ms\tremaining: 521ms\n",
      "630:\tlearn: 0.2682053\ttotal: 889ms\tremaining: 520ms\n",
      "631:\tlearn: 0.2679562\ttotal: 890ms\tremaining: 518ms\n",
      "632:\tlearn: 0.2678710\ttotal: 892ms\tremaining: 517ms\n",
      "633:\tlearn: 0.2676250\ttotal: 893ms\tremaining: 516ms\n",
      "634:\tlearn: 0.2674543\ttotal: 895ms\tremaining: 514ms\n",
      "635:\tlearn: 0.2673390\ttotal: 896ms\tremaining: 513ms\n",
      "636:\tlearn: 0.2672740\ttotal: 897ms\tremaining: 511ms\n",
      "637:\tlearn: 0.2672287\ttotal: 899ms\tremaining: 510ms\n",
      "638:\tlearn: 0.2672063\ttotal: 900ms\tremaining: 508ms\n",
      "639:\tlearn: 0.2670476\ttotal: 901ms\tremaining: 507ms\n",
      "640:\tlearn: 0.2668130\ttotal: 903ms\tremaining: 506ms\n",
      "641:\tlearn: 0.2667989\ttotal: 903ms\tremaining: 504ms\n",
      "642:\tlearn: 0.2663734\ttotal: 905ms\tremaining: 502ms\n",
      "643:\tlearn: 0.2660103\ttotal: 906ms\tremaining: 501ms\n",
      "644:\tlearn: 0.2659486\ttotal: 907ms\tremaining: 499ms\n",
      "645:\tlearn: 0.2656777\ttotal: 909ms\tremaining: 498ms\n",
      "646:\tlearn: 0.2655940\ttotal: 910ms\tremaining: 497ms\n",
      "647:\tlearn: 0.2654686\ttotal: 911ms\tremaining: 495ms\n",
      "648:\tlearn: 0.2653091\ttotal: 913ms\tremaining: 494ms\n",
      "649:\tlearn: 0.2651618\ttotal: 914ms\tremaining: 492ms\n",
      "650:\tlearn: 0.2650375\ttotal: 916ms\tremaining: 491ms\n",
      "651:\tlearn: 0.2648988\ttotal: 917ms\tremaining: 489ms\n",
      "652:\tlearn: 0.2646704\ttotal: 918ms\tremaining: 488ms\n",
      "653:\tlearn: 0.2645638\ttotal: 920ms\tremaining: 486ms\n",
      "654:\tlearn: 0.2645206\ttotal: 921ms\tremaining: 485ms\n",
      "655:\tlearn: 0.2643895\ttotal: 922ms\tremaining: 483ms\n",
      "656:\tlearn: 0.2643609\ttotal: 923ms\tremaining: 482ms\n",
      "657:\tlearn: 0.2642671\ttotal: 924ms\tremaining: 480ms\n",
      "658:\tlearn: 0.2641866\ttotal: 925ms\tremaining: 479ms\n",
      "659:\tlearn: 0.2641407\ttotal: 926ms\tremaining: 477ms\n",
      "660:\tlearn: 0.2640053\ttotal: 928ms\tremaining: 476ms\n",
      "661:\tlearn: 0.2637911\ttotal: 929ms\tremaining: 474ms\n",
      "662:\tlearn: 0.2636618\ttotal: 930ms\tremaining: 473ms\n",
      "663:\tlearn: 0.2635737\ttotal: 932ms\tremaining: 471ms\n",
      "664:\tlearn: 0.2634220\ttotal: 933ms\tremaining: 470ms\n",
      "665:\tlearn: 0.2633036\ttotal: 934ms\tremaining: 468ms\n",
      "666:\tlearn: 0.2631984\ttotal: 935ms\tremaining: 467ms\n",
      "667:\tlearn: 0.2629166\ttotal: 937ms\tremaining: 466ms\n",
      "668:\tlearn: 0.2627425\ttotal: 938ms\tremaining: 464ms\n",
      "669:\tlearn: 0.2626335\ttotal: 939ms\tremaining: 463ms\n",
      "670:\tlearn: 0.2624560\ttotal: 941ms\tremaining: 461ms\n",
      "671:\tlearn: 0.2622624\ttotal: 942ms\tremaining: 460ms\n",
      "672:\tlearn: 0.2622418\ttotal: 943ms\tremaining: 458ms\n",
      "673:\tlearn: 0.2620229\ttotal: 944ms\tremaining: 457ms\n",
      "674:\tlearn: 0.2619083\ttotal: 945ms\tremaining: 455ms\n",
      "675:\tlearn: 0.2618191\ttotal: 947ms\tremaining: 454ms\n",
      "676:\tlearn: 0.2617045\ttotal: 948ms\tremaining: 452ms\n",
      "677:\tlearn: 0.2616548\ttotal: 949ms\tremaining: 451ms\n",
      "678:\tlearn: 0.2615117\ttotal: 951ms\tremaining: 449ms\n",
      "679:\tlearn: 0.2613831\ttotal: 952ms\tremaining: 448ms\n",
      "680:\tlearn: 0.2613102\ttotal: 953ms\tremaining: 446ms\n",
      "681:\tlearn: 0.2611971\ttotal: 954ms\tremaining: 445ms\n",
      "682:\tlearn: 0.2610695\ttotal: 955ms\tremaining: 443ms\n",
      "683:\tlearn: 0.2608497\ttotal: 957ms\tremaining: 442ms\n",
      "684:\tlearn: 0.2607581\ttotal: 958ms\tremaining: 441ms\n",
      "685:\tlearn: 0.2606217\ttotal: 960ms\tremaining: 439ms\n",
      "686:\tlearn: 0.2604466\ttotal: 961ms\tremaining: 438ms\n",
      "687:\tlearn: 0.2604140\ttotal: 963ms\tremaining: 436ms\n",
      "688:\tlearn: 0.2602928\ttotal: 964ms\tremaining: 435ms\n",
      "689:\tlearn: 0.2601877\ttotal: 965ms\tremaining: 434ms\n",
      "690:\tlearn: 0.2600762\ttotal: 967ms\tremaining: 432ms\n",
      "691:\tlearn: 0.2599633\ttotal: 968ms\tremaining: 431ms\n",
      "692:\tlearn: 0.2597789\ttotal: 969ms\tremaining: 429ms\n",
      "693:\tlearn: 0.2597703\ttotal: 970ms\tremaining: 428ms\n",
      "694:\tlearn: 0.2597567\ttotal: 971ms\tremaining: 426ms\n",
      "695:\tlearn: 0.2595794\ttotal: 972ms\tremaining: 425ms\n",
      "696:\tlearn: 0.2593300\ttotal: 973ms\tremaining: 423ms\n",
      "697:\tlearn: 0.2592269\ttotal: 975ms\tremaining: 422ms\n",
      "698:\tlearn: 0.2589514\ttotal: 976ms\tremaining: 420ms\n",
      "699:\tlearn: 0.2588556\ttotal: 977ms\tremaining: 419ms\n",
      "700:\tlearn: 0.2584865\ttotal: 979ms\tremaining: 417ms\n",
      "701:\tlearn: 0.2584140\ttotal: 980ms\tremaining: 416ms\n",
      "702:\tlearn: 0.2582046\ttotal: 981ms\tremaining: 415ms\n",
      "703:\tlearn: 0.2579842\ttotal: 983ms\tremaining: 413ms\n",
      "704:\tlearn: 0.2579248\ttotal: 984ms\tremaining: 412ms\n",
      "705:\tlearn: 0.2574860\ttotal: 985ms\tremaining: 410ms\n",
      "706:\tlearn: 0.2574685\ttotal: 986ms\tremaining: 409ms\n",
      "707:\tlearn: 0.2572044\ttotal: 988ms\tremaining: 407ms\n",
      "708:\tlearn: 0.2570118\ttotal: 989ms\tremaining: 406ms\n",
      "709:\tlearn: 0.2568559\ttotal: 990ms\tremaining: 405ms\n",
      "710:\tlearn: 0.2566834\ttotal: 992ms\tremaining: 403ms\n",
      "711:\tlearn: 0.2564706\ttotal: 993ms\tremaining: 402ms\n",
      "712:\tlearn: 0.2563840\ttotal: 994ms\tremaining: 400ms\n",
      "713:\tlearn: 0.2562476\ttotal: 996ms\tremaining: 399ms\n",
      "714:\tlearn: 0.2560662\ttotal: 998ms\tremaining: 398ms\n",
      "715:\tlearn: 0.2559078\ttotal: 999ms\tremaining: 396ms\n",
      "716:\tlearn: 0.2557816\ttotal: 1s\tremaining: 395ms\n",
      "717:\tlearn: 0.2553890\ttotal: 1s\tremaining: 394ms\n",
      "718:\tlearn: 0.2553731\ttotal: 1s\tremaining: 392ms\n",
      "719:\tlearn: 0.2552026\ttotal: 1s\tremaining: 391ms\n",
      "720:\tlearn: 0.2549797\ttotal: 1s\tremaining: 389ms\n",
      "721:\tlearn: 0.2548031\ttotal: 1.01s\tremaining: 388ms\n",
      "722:\tlearn: 0.2547420\ttotal: 1.01s\tremaining: 386ms\n",
      "723:\tlearn: 0.2545769\ttotal: 1.01s\tremaining: 385ms\n",
      "724:\tlearn: 0.2544091\ttotal: 1.01s\tremaining: 384ms\n",
      "725:\tlearn: 0.2540288\ttotal: 1.01s\tremaining: 382ms\n",
      "726:\tlearn: 0.2538072\ttotal: 1.01s\tremaining: 381ms\n",
      "727:\tlearn: 0.2536178\ttotal: 1.01s\tremaining: 379ms\n",
      "728:\tlearn: 0.2534635\ttotal: 1.02s\tremaining: 378ms\n",
      "729:\tlearn: 0.2533530\ttotal: 1.02s\tremaining: 377ms\n",
      "730:\tlearn: 0.2530829\ttotal: 1.02s\tremaining: 375ms\n",
      "731:\tlearn: 0.2529896\ttotal: 1.02s\tremaining: 374ms\n",
      "732:\tlearn: 0.2527156\ttotal: 1.02s\tremaining: 372ms\n",
      "733:\tlearn: 0.2525580\ttotal: 1.02s\tremaining: 371ms\n",
      "734:\tlearn: 0.2524956\ttotal: 1.02s\tremaining: 370ms\n",
      "735:\tlearn: 0.2522710\ttotal: 1.03s\tremaining: 368ms\n",
      "736:\tlearn: 0.2521491\ttotal: 1.03s\tremaining: 367ms\n",
      "737:\tlearn: 0.2519850\ttotal: 1.03s\tremaining: 365ms\n",
      "738:\tlearn: 0.2518385\ttotal: 1.03s\tremaining: 364ms\n",
      "739:\tlearn: 0.2516684\ttotal: 1.03s\tremaining: 363ms\n",
      "740:\tlearn: 0.2515537\ttotal: 1.03s\tremaining: 361ms\n",
      "741:\tlearn: 0.2514291\ttotal: 1.03s\tremaining: 360ms\n",
      "742:\tlearn: 0.2513236\ttotal: 1.03s\tremaining: 358ms\n",
      "743:\tlearn: 0.2511832\ttotal: 1.04s\tremaining: 357ms\n",
      "744:\tlearn: 0.2510909\ttotal: 1.04s\tremaining: 355ms\n",
      "745:\tlearn: 0.2509626\ttotal: 1.04s\tremaining: 354ms\n",
      "746:\tlearn: 0.2508015\ttotal: 1.04s\tremaining: 353ms\n",
      "747:\tlearn: 0.2506847\ttotal: 1.04s\tremaining: 351ms\n",
      "748:\tlearn: 0.2506141\ttotal: 1.04s\tremaining: 350ms\n",
      "749:\tlearn: 0.2505242\ttotal: 1.04s\tremaining: 348ms\n",
      "750:\tlearn: 0.2503020\ttotal: 1.05s\tremaining: 347ms\n",
      "751:\tlearn: 0.2502306\ttotal: 1.05s\tremaining: 346ms\n",
      "752:\tlearn: 0.2500911\ttotal: 1.05s\tremaining: 344ms\n",
      "753:\tlearn: 0.2499692\ttotal: 1.05s\tremaining: 343ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754:\tlearn: 0.2497531\ttotal: 1.05s\tremaining: 341ms\n",
      "755:\tlearn: 0.2495787\ttotal: 1.05s\tremaining: 340ms\n",
      "756:\tlearn: 0.2494579\ttotal: 1.05s\tremaining: 339ms\n",
      "757:\tlearn: 0.2493292\ttotal: 1.06s\tremaining: 337ms\n",
      "758:\tlearn: 0.2492193\ttotal: 1.06s\tremaining: 336ms\n",
      "759:\tlearn: 0.2491069\ttotal: 1.06s\tremaining: 335ms\n",
      "760:\tlearn: 0.2490402\ttotal: 1.06s\tremaining: 333ms\n",
      "761:\tlearn: 0.2489577\ttotal: 1.06s\tremaining: 332ms\n",
      "762:\tlearn: 0.2489228\ttotal: 1.06s\tremaining: 330ms\n",
      "763:\tlearn: 0.2488174\ttotal: 1.06s\tremaining: 329ms\n",
      "764:\tlearn: 0.2486620\ttotal: 1.07s\tremaining: 328ms\n",
      "765:\tlearn: 0.2485410\ttotal: 1.07s\tremaining: 326ms\n",
      "766:\tlearn: 0.2484010\ttotal: 1.07s\tremaining: 325ms\n",
      "767:\tlearn: 0.2482357\ttotal: 1.07s\tremaining: 323ms\n",
      "768:\tlearn: 0.2481600\ttotal: 1.07s\tremaining: 322ms\n",
      "769:\tlearn: 0.2480189\ttotal: 1.07s\tremaining: 321ms\n",
      "770:\tlearn: 0.2478572\ttotal: 1.07s\tremaining: 319ms\n",
      "771:\tlearn: 0.2477982\ttotal: 1.08s\tremaining: 318ms\n",
      "772:\tlearn: 0.2477057\ttotal: 1.08s\tremaining: 317ms\n",
      "773:\tlearn: 0.2475644\ttotal: 1.08s\tremaining: 315ms\n",
      "774:\tlearn: 0.2474626\ttotal: 1.08s\tremaining: 314ms\n",
      "775:\tlearn: 0.2473643\ttotal: 1.08s\tremaining: 313ms\n",
      "776:\tlearn: 0.2472315\ttotal: 1.08s\tremaining: 311ms\n",
      "777:\tlearn: 0.2471208\ttotal: 1.08s\tremaining: 310ms\n",
      "778:\tlearn: 0.2469616\ttotal: 1.09s\tremaining: 308ms\n",
      "779:\tlearn: 0.2467151\ttotal: 1.09s\tremaining: 307ms\n",
      "780:\tlearn: 0.2465182\ttotal: 1.09s\tremaining: 306ms\n",
      "781:\tlearn: 0.2463989\ttotal: 1.09s\tremaining: 304ms\n",
      "782:\tlearn: 0.2462261\ttotal: 1.09s\tremaining: 303ms\n",
      "783:\tlearn: 0.2461243\ttotal: 1.09s\tremaining: 301ms\n",
      "784:\tlearn: 0.2460510\ttotal: 1.09s\tremaining: 300ms\n",
      "785:\tlearn: 0.2459658\ttotal: 1.1s\tremaining: 299ms\n",
      "786:\tlearn: 0.2458601\ttotal: 1.1s\tremaining: 297ms\n",
      "787:\tlearn: 0.2458137\ttotal: 1.1s\tremaining: 296ms\n",
      "788:\tlearn: 0.2457287\ttotal: 1.1s\tremaining: 294ms\n",
      "789:\tlearn: 0.2456968\ttotal: 1.1s\tremaining: 293ms\n",
      "790:\tlearn: 0.2456173\ttotal: 1.1s\tremaining: 292ms\n",
      "791:\tlearn: 0.2453351\ttotal: 1.1s\tremaining: 290ms\n",
      "792:\tlearn: 0.2449575\ttotal: 1.11s\tremaining: 289ms\n",
      "793:\tlearn: 0.2448847\ttotal: 1.11s\tremaining: 287ms\n",
      "794:\tlearn: 0.2447501\ttotal: 1.11s\tremaining: 286ms\n",
      "795:\tlearn: 0.2446451\ttotal: 1.11s\tremaining: 285ms\n",
      "796:\tlearn: 0.2445085\ttotal: 1.11s\tremaining: 283ms\n",
      "797:\tlearn: 0.2443060\ttotal: 1.11s\tremaining: 282ms\n",
      "798:\tlearn: 0.2442248\ttotal: 1.11s\tremaining: 281ms\n",
      "799:\tlearn: 0.2441828\ttotal: 1.12s\tremaining: 279ms\n",
      "800:\tlearn: 0.2440314\ttotal: 1.12s\tremaining: 278ms\n",
      "801:\tlearn: 0.2438962\ttotal: 1.12s\tremaining: 276ms\n",
      "802:\tlearn: 0.2438193\ttotal: 1.12s\tremaining: 275ms\n",
      "803:\tlearn: 0.2437250\ttotal: 1.12s\tremaining: 274ms\n",
      "804:\tlearn: 0.2436130\ttotal: 1.12s\tremaining: 272ms\n",
      "805:\tlearn: 0.2434940\ttotal: 1.13s\tremaining: 271ms\n",
      "806:\tlearn: 0.2433526\ttotal: 1.13s\tremaining: 269ms\n",
      "807:\tlearn: 0.2432975\ttotal: 1.13s\tremaining: 268ms\n",
      "808:\tlearn: 0.2431468\ttotal: 1.13s\tremaining: 267ms\n",
      "809:\tlearn: 0.2430032\ttotal: 1.13s\tremaining: 265ms\n",
      "810:\tlearn: 0.2428878\ttotal: 1.13s\tremaining: 264ms\n",
      "811:\tlearn: 0.2428293\ttotal: 1.13s\tremaining: 262ms\n",
      "812:\tlearn: 0.2426628\ttotal: 1.13s\tremaining: 261ms\n",
      "813:\tlearn: 0.2424736\ttotal: 1.14s\tremaining: 259ms\n",
      "814:\tlearn: 0.2424156\ttotal: 1.14s\tremaining: 258ms\n",
      "815:\tlearn: 0.2422535\ttotal: 1.14s\tremaining: 257ms\n",
      "816:\tlearn: 0.2422235\ttotal: 1.14s\tremaining: 255ms\n",
      "817:\tlearn: 0.2419599\ttotal: 1.14s\tremaining: 254ms\n",
      "818:\tlearn: 0.2418328\ttotal: 1.14s\tremaining: 252ms\n",
      "819:\tlearn: 0.2417664\ttotal: 1.14s\tremaining: 251ms\n",
      "820:\tlearn: 0.2416658\ttotal: 1.14s\tremaining: 250ms\n",
      "821:\tlearn: 0.2416077\ttotal: 1.15s\tremaining: 248ms\n",
      "822:\tlearn: 0.2415232\ttotal: 1.15s\tremaining: 247ms\n",
      "823:\tlearn: 0.2413589\ttotal: 1.15s\tremaining: 245ms\n",
      "824:\tlearn: 0.2413037\ttotal: 1.15s\tremaining: 244ms\n",
      "825:\tlearn: 0.2411545\ttotal: 1.15s\tremaining: 243ms\n",
      "826:\tlearn: 0.2409514\ttotal: 1.15s\tremaining: 241ms\n",
      "827:\tlearn: 0.2408100\ttotal: 1.15s\tremaining: 240ms\n",
      "828:\tlearn: 0.2407403\ttotal: 1.16s\tremaining: 238ms\n",
      "829:\tlearn: 0.2404979\ttotal: 1.16s\tremaining: 237ms\n",
      "830:\tlearn: 0.2402998\ttotal: 1.16s\tremaining: 236ms\n",
      "831:\tlearn: 0.2402197\ttotal: 1.16s\tremaining: 234ms\n",
      "832:\tlearn: 0.2400677\ttotal: 1.16s\tremaining: 233ms\n",
      "833:\tlearn: 0.2399577\ttotal: 1.16s\tremaining: 231ms\n",
      "834:\tlearn: 0.2398273\ttotal: 1.16s\tremaining: 230ms\n",
      "835:\tlearn: 0.2397758\ttotal: 1.16s\tremaining: 229ms\n",
      "836:\tlearn: 0.2395752\ttotal: 1.17s\tremaining: 227ms\n",
      "837:\tlearn: 0.2394780\ttotal: 1.17s\tremaining: 226ms\n",
      "838:\tlearn: 0.2394080\ttotal: 1.17s\tremaining: 224ms\n",
      "839:\tlearn: 0.2393551\ttotal: 1.17s\tremaining: 223ms\n",
      "840:\tlearn: 0.2392569\ttotal: 1.17s\tremaining: 222ms\n",
      "841:\tlearn: 0.2391372\ttotal: 1.17s\tremaining: 220ms\n",
      "842:\tlearn: 0.2389861\ttotal: 1.17s\tremaining: 219ms\n",
      "843:\tlearn: 0.2388442\ttotal: 1.18s\tremaining: 217ms\n",
      "844:\tlearn: 0.2387802\ttotal: 1.18s\tremaining: 216ms\n",
      "845:\tlearn: 0.2387244\ttotal: 1.18s\tremaining: 214ms\n",
      "846:\tlearn: 0.2385961\ttotal: 1.18s\tremaining: 213ms\n",
      "847:\tlearn: 0.2385515\ttotal: 1.18s\tremaining: 212ms\n",
      "848:\tlearn: 0.2383360\ttotal: 1.18s\tremaining: 210ms\n",
      "849:\tlearn: 0.2381232\ttotal: 1.18s\tremaining: 209ms\n",
      "850:\tlearn: 0.2379354\ttotal: 1.19s\tremaining: 207ms\n",
      "851:\tlearn: 0.2378706\ttotal: 1.19s\tremaining: 206ms\n",
      "852:\tlearn: 0.2377994\ttotal: 1.19s\tremaining: 205ms\n",
      "853:\tlearn: 0.2377383\ttotal: 1.19s\tremaining: 203ms\n",
      "854:\tlearn: 0.2374847\ttotal: 1.19s\tremaining: 202ms\n",
      "855:\tlearn: 0.2373811\ttotal: 1.19s\tremaining: 200ms\n",
      "856:\tlearn: 0.2372912\ttotal: 1.19s\tremaining: 199ms\n",
      "857:\tlearn: 0.2371777\ttotal: 1.19s\tremaining: 198ms\n",
      "858:\tlearn: 0.2370647\ttotal: 1.2s\tremaining: 196ms\n",
      "859:\tlearn: 0.2369921\ttotal: 1.2s\tremaining: 195ms\n",
      "860:\tlearn: 0.2367908\ttotal: 1.2s\tremaining: 193ms\n",
      "861:\tlearn: 0.2366752\ttotal: 1.2s\tremaining: 192ms\n",
      "862:\tlearn: 0.2366638\ttotal: 1.2s\tremaining: 191ms\n",
      "863:\tlearn: 0.2364912\ttotal: 1.2s\tremaining: 189ms\n",
      "864:\tlearn: 0.2364112\ttotal: 1.2s\tremaining: 188ms\n",
      "865:\tlearn: 0.2362386\ttotal: 1.2s\tremaining: 186ms\n",
      "866:\tlearn: 0.2361646\ttotal: 1.21s\tremaining: 185ms\n",
      "867:\tlearn: 0.2360536\ttotal: 1.21s\tremaining: 184ms\n",
      "868:\tlearn: 0.2359244\ttotal: 1.21s\tremaining: 182ms\n",
      "869:\tlearn: 0.2357740\ttotal: 1.21s\tremaining: 181ms\n",
      "870:\tlearn: 0.2356782\ttotal: 1.21s\tremaining: 179ms\n",
      "871:\tlearn: 0.2356449\ttotal: 1.21s\tremaining: 178ms\n",
      "872:\tlearn: 0.2355585\ttotal: 1.21s\tremaining: 177ms\n",
      "873:\tlearn: 0.2354414\ttotal: 1.22s\tremaining: 175ms\n",
      "874:\tlearn: 0.2353593\ttotal: 1.22s\tremaining: 174ms\n",
      "875:\tlearn: 0.2350099\ttotal: 1.22s\tremaining: 172ms\n",
      "876:\tlearn: 0.2349798\ttotal: 1.22s\tremaining: 171ms\n",
      "877:\tlearn: 0.2348332\ttotal: 1.22s\tremaining: 170ms\n",
      "878:\tlearn: 0.2347911\ttotal: 1.22s\tremaining: 168ms\n",
      "879:\tlearn: 0.2345985\ttotal: 1.22s\tremaining: 167ms\n",
      "880:\tlearn: 0.2344625\ttotal: 1.22s\tremaining: 165ms\n",
      "881:\tlearn: 0.2343999\ttotal: 1.23s\tremaining: 164ms\n",
      "882:\tlearn: 0.2343227\ttotal: 1.23s\tremaining: 163ms\n",
      "883:\tlearn: 0.2342649\ttotal: 1.23s\tremaining: 161ms\n",
      "884:\tlearn: 0.2342359\ttotal: 1.23s\tremaining: 160ms\n",
      "885:\tlearn: 0.2342048\ttotal: 1.23s\tremaining: 159ms\n",
      "886:\tlearn: 0.2341609\ttotal: 1.23s\tremaining: 157ms\n",
      "887:\tlearn: 0.2340259\ttotal: 1.24s\tremaining: 156ms\n",
      "888:\tlearn: 0.2339361\ttotal: 1.24s\tremaining: 155ms\n",
      "889:\tlearn: 0.2337888\ttotal: 1.24s\tremaining: 153ms\n",
      "890:\tlearn: 0.2335993\ttotal: 1.24s\tremaining: 152ms\n",
      "891:\tlearn: 0.2335388\ttotal: 1.24s\tremaining: 151ms\n",
      "892:\tlearn: 0.2334457\ttotal: 1.25s\tremaining: 149ms\n",
      "893:\tlearn: 0.2332631\ttotal: 1.25s\tremaining: 148ms\n",
      "894:\tlearn: 0.2331704\ttotal: 1.25s\tremaining: 147ms\n",
      "895:\tlearn: 0.2329484\ttotal: 1.25s\tremaining: 145ms\n",
      "896:\tlearn: 0.2328403\ttotal: 1.25s\tremaining: 144ms\n",
      "897:\tlearn: 0.2327310\ttotal: 1.25s\tremaining: 142ms\n",
      "898:\tlearn: 0.2325090\ttotal: 1.25s\tremaining: 141ms\n",
      "899:\tlearn: 0.2323637\ttotal: 1.25s\tremaining: 139ms\n",
      "900:\tlearn: 0.2322756\ttotal: 1.26s\tremaining: 138ms\n",
      "901:\tlearn: 0.2321816\ttotal: 1.26s\tremaining: 137ms\n",
      "902:\tlearn: 0.2319413\ttotal: 1.26s\tremaining: 135ms\n",
      "903:\tlearn: 0.2318611\ttotal: 1.26s\tremaining: 134ms\n",
      "904:\tlearn: 0.2317350\ttotal: 1.26s\tremaining: 133ms\n",
      "905:\tlearn: 0.2316770\ttotal: 1.26s\tremaining: 131ms\n",
      "906:\tlearn: 0.2313985\ttotal: 1.26s\tremaining: 130ms\n",
      "907:\tlearn: 0.2313857\ttotal: 1.26s\tremaining: 128ms\n",
      "908:\tlearn: 0.2312415\ttotal: 1.27s\tremaining: 127ms\n",
      "909:\tlearn: 0.2310854\ttotal: 1.27s\tremaining: 125ms\n",
      "910:\tlearn: 0.2309834\ttotal: 1.27s\tremaining: 124ms\n",
      "911:\tlearn: 0.2308745\ttotal: 1.27s\tremaining: 123ms\n",
      "912:\tlearn: 0.2307430\ttotal: 1.27s\tremaining: 121ms\n",
      "913:\tlearn: 0.2306779\ttotal: 1.27s\tremaining: 120ms\n",
      "914:\tlearn: 0.2305683\ttotal: 1.27s\tremaining: 118ms\n",
      "915:\tlearn: 0.2304999\ttotal: 1.28s\tremaining: 117ms\n",
      "916:\tlearn: 0.2303698\ttotal: 1.28s\tremaining: 116ms\n",
      "917:\tlearn: 0.2302337\ttotal: 1.28s\tremaining: 114ms\n",
      "918:\tlearn: 0.2301384\ttotal: 1.28s\tremaining: 113ms\n",
      "919:\tlearn: 0.2300039\ttotal: 1.28s\tremaining: 112ms\n",
      "920:\tlearn: 0.2298942\ttotal: 1.28s\tremaining: 110ms\n",
      "921:\tlearn: 0.2296960\ttotal: 1.28s\tremaining: 109ms\n",
      "922:\tlearn: 0.2295793\ttotal: 1.29s\tremaining: 107ms\n",
      "923:\tlearn: 0.2294619\ttotal: 1.29s\tremaining: 106ms\n",
      "924:\tlearn: 0.2293088\ttotal: 1.29s\tremaining: 105ms\n",
      "925:\tlearn: 0.2290726\ttotal: 1.29s\tremaining: 103ms\n",
      "926:\tlearn: 0.2288578\ttotal: 1.29s\tremaining: 102ms\n",
      "927:\tlearn: 0.2288105\ttotal: 1.29s\tremaining: 100ms\n",
      "928:\tlearn: 0.2287227\ttotal: 1.29s\tremaining: 98.9ms\n",
      "929:\tlearn: 0.2285371\ttotal: 1.29s\tremaining: 97.5ms\n",
      "930:\tlearn: 0.2284032\ttotal: 1.3s\tremaining: 96.1ms\n",
      "931:\tlearn: 0.2282921\ttotal: 1.3s\tremaining: 94.7ms\n",
      "932:\tlearn: 0.2280478\ttotal: 1.3s\tremaining: 93.3ms\n",
      "933:\tlearn: 0.2279721\ttotal: 1.3s\tremaining: 92ms\n",
      "934:\tlearn: 0.2278734\ttotal: 1.3s\tremaining: 90.6ms\n",
      "935:\tlearn: 0.2277585\ttotal: 1.3s\tremaining: 89.2ms\n",
      "936:\tlearn: 0.2276651\ttotal: 1.3s\tremaining: 87.8ms\n",
      "937:\tlearn: 0.2275964\ttotal: 1.31s\tremaining: 86.4ms\n",
      "938:\tlearn: 0.2273688\ttotal: 1.31s\tremaining: 85ms\n",
      "939:\tlearn: 0.2272966\ttotal: 1.31s\tremaining: 83.6ms\n",
      "940:\tlearn: 0.2271414\ttotal: 1.31s\tremaining: 82.2ms\n",
      "941:\tlearn: 0.2270247\ttotal: 1.31s\tremaining: 80.8ms\n",
      "942:\tlearn: 0.2270037\ttotal: 1.31s\tremaining: 79.4ms\n",
      "943:\tlearn: 0.2268715\ttotal: 1.31s\tremaining: 78ms\n",
      "944:\tlearn: 0.2267609\ttotal: 1.32s\tremaining: 76.6ms\n",
      "945:\tlearn: 0.2266369\ttotal: 1.32s\tremaining: 75.2ms\n",
      "946:\tlearn: 0.2265088\ttotal: 1.32s\tremaining: 73.8ms\n",
      "947:\tlearn: 0.2263774\ttotal: 1.32s\tremaining: 72.4ms\n",
      "948:\tlearn: 0.2262231\ttotal: 1.32s\tremaining: 71ms\n",
      "949:\tlearn: 0.2261498\ttotal: 1.32s\tremaining: 69.6ms\n",
      "950:\tlearn: 0.2261142\ttotal: 1.32s\tremaining: 68.2ms\n",
      "951:\tlearn: 0.2259027\ttotal: 1.32s\tremaining: 66.8ms\n",
      "952:\tlearn: 0.2257594\ttotal: 1.33s\tremaining: 65.4ms\n",
      "953:\tlearn: 0.2257144\ttotal: 1.33s\tremaining: 64ms\n",
      "954:\tlearn: 0.2256583\ttotal: 1.33s\tremaining: 62.7ms\n",
      "955:\tlearn: 0.2256283\ttotal: 1.33s\tremaining: 61.3ms\n",
      "956:\tlearn: 0.2255898\ttotal: 1.33s\tremaining: 59.9ms\n",
      "957:\tlearn: 0.2254216\ttotal: 1.33s\tremaining: 58.5ms\n",
      "958:\tlearn: 0.2253493\ttotal: 1.33s\tremaining: 57.1ms\n",
      "959:\tlearn: 0.2251866\ttotal: 1.34s\tremaining: 55.7ms\n",
      "960:\tlearn: 0.2250816\ttotal: 1.34s\tremaining: 54.3ms\n",
      "961:\tlearn: 0.2249968\ttotal: 1.34s\tremaining: 52.9ms\n",
      "962:\tlearn: 0.2249205\ttotal: 1.34s\tremaining: 51.5ms\n",
      "963:\tlearn: 0.2248459\ttotal: 1.34s\tremaining: 50.1ms\n",
      "964:\tlearn: 0.2246250\ttotal: 1.34s\tremaining: 48.7ms\n",
      "965:\tlearn: 0.2245253\ttotal: 1.34s\tremaining: 47.3ms\n",
      "966:\tlearn: 0.2244678\ttotal: 1.35s\tremaining: 46ms\n",
      "967:\tlearn: 0.2242903\ttotal: 1.35s\tremaining: 44.6ms\n",
      "968:\tlearn: 0.2242375\ttotal: 1.35s\tremaining: 43.2ms\n",
      "969:\tlearn: 0.2241627\ttotal: 1.35s\tremaining: 41.8ms\n",
      "970:\tlearn: 0.2239726\ttotal: 1.35s\tremaining: 40.4ms\n",
      "971:\tlearn: 0.2238514\ttotal: 1.35s\tremaining: 39ms\n",
      "972:\tlearn: 0.2237508\ttotal: 1.35s\tremaining: 37.6ms\n",
      "973:\tlearn: 0.2236273\ttotal: 1.36s\tremaining: 36.2ms\n",
      "974:\tlearn: 0.2234000\ttotal: 1.36s\tremaining: 34.8ms\n",
      "975:\tlearn: 0.2233538\ttotal: 1.36s\tremaining: 33.4ms\n",
      "976:\tlearn: 0.2231641\ttotal: 1.36s\tremaining: 32ms\n",
      "977:\tlearn: 0.2230093\ttotal: 1.36s\tremaining: 30.6ms\n",
      "978:\tlearn: 0.2229378\ttotal: 1.36s\tremaining: 29.2ms\n",
      "979:\tlearn: 0.2228075\ttotal: 1.36s\tremaining: 27.8ms\n",
      "980:\tlearn: 0.2224746\ttotal: 1.36s\tremaining: 26.4ms\n",
      "981:\tlearn: 0.2223554\ttotal: 1.37s\tremaining: 25.1ms\n",
      "982:\tlearn: 0.2222556\ttotal: 1.37s\tremaining: 23.7ms\n",
      "983:\tlearn: 0.2222241\ttotal: 1.37s\tremaining: 22.3ms\n",
      "984:\tlearn: 0.2221765\ttotal: 1.37s\tremaining: 20.9ms\n",
      "985:\tlearn: 0.2221283\ttotal: 1.37s\tremaining: 19.5ms\n",
      "986:\tlearn: 0.2221019\ttotal: 1.37s\tremaining: 18.1ms\n",
      "987:\tlearn: 0.2219460\ttotal: 1.38s\tremaining: 16.7ms\n",
      "988:\tlearn: 0.2218052\ttotal: 1.38s\tremaining: 15.3ms\n",
      "989:\tlearn: 0.2217576\ttotal: 1.38s\tremaining: 13.9ms\n",
      "990:\tlearn: 0.2216153\ttotal: 1.38s\tremaining: 12.5ms\n",
      "991:\tlearn: 0.2213976\ttotal: 1.38s\tremaining: 11.1ms\n",
      "992:\tlearn: 0.2213567\ttotal: 1.38s\tremaining: 9.74ms\n",
      "993:\tlearn: 0.2212607\ttotal: 1.38s\tremaining: 8.35ms\n",
      "994:\tlearn: 0.2211248\ttotal: 1.38s\tremaining: 6.96ms\n",
      "995:\tlearn: 0.2209354\ttotal: 1.39s\tremaining: 5.57ms\n",
      "996:\tlearn: 0.2206282\ttotal: 1.39s\tremaining: 4.17ms\n",
      "997:\tlearn: 0.2205561\ttotal: 1.39s\tremaining: 2.78ms\n",
      "998:\tlearn: 0.2203435\ttotal: 1.39s\tremaining: 1.39ms\n",
      "999:\tlearn: 0.2202285\ttotal: 1.39s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision= 0.938\n",
      "test precision= 0.83\n",
      "train f1 score= 0.927\n",
      "test f1 score= 0.825\n",
      "train accuracy score= 0.933\n",
      "test accuracy score= 0.839\n"
     ]
    }
   ],
   "source": [
    "catb.fit(X_train, y_train)\n",
    "y_pred_catb_train = catb.predict(X_train)\n",
    "y_pred_catb_test = catb.predict(X_test)\n",
    "print(\"train precision=\", np.round(metrics.precision_score(y_train, y_pred_catb_train, average='macro'),3))\n",
    "print(\"test precision=\", np.round(metrics.precision_score(y_test, y_pred_catb_test, average='macro'),3))\n",
    "f1_train = f1_score(y_train, y_pred_catb_train, average='macro')\n",
    "f1_test = f1_score(y_test, y_pred_catb_test, average='macro')\n",
    "print(\"train f1 score=\", np.round(f1_train,3))\n",
    "print(\"test f1 score=\", np.round(f1_test,3))\n",
    "Accuracy_train = accuracy_score(y_train, y_pred_catb_train)\n",
    "Accuracy_test = accuracy_score(y_test, y_pred_catb_test)\n",
    "print(\"train accuracy score=\", np.round(Accuracy_train,3))\n",
    "print(\"test accuracy score=\", np.round(Accuracy_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ad986e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x450 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(catb)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e7180556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.840 (0.027)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hist = HistGradientBoostingClassifier(n_iter_no_change=10, early_stopping=True, random_state=262)\n",
    "cv = KFold(n_splits=5, random_state=262, shuffle=True)\n",
    "# create model\n",
    "model = hist\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0d84aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision= 0.947\n",
      "test precision= 0.806\n",
      "train f1 score= 0.942\n",
      "test f1 score= 0.807\n",
      "train accuracy score= 0.946\n",
      "test accuracy score= 0.82\n"
     ]
    }
   ],
   "source": [
    "hist.fit(X_train, y_train)\n",
    "y_pred_hist_train = hist.predict(X_train)\n",
    "y_pred_hist_test = hist.predict(X_test)\n",
    "print(\"train precision=\", np.round(metrics.precision_score(y_train, y_pred_hist_train, average='macro'),3))\n",
    "print(\"test precision=\", np.round(metrics.precision_score(y_test, y_pred_hist_test, average='macro'),3))\n",
    "f1_train = f1_score(y_train, y_pred_hist_train, average='macro')\n",
    "f1_test = f1_score(y_test, y_pred_hist_test, average='macro')\n",
    "print(\"train f1 score=\", np.round(f1_train,3))\n",
    "print(\"test f1 score=\", np.round(f1_test,3))\n",
    "Accuracy_train = accuracy_score(y_train, y_pred_hist_train)\n",
    "Accuracy_test = accuracy_score(y_test, y_pred_hist_test)\n",
    "print(\"train accuracy score=\", np.round(Accuracy_train,3))\n",
    "print(\"test accuracy score=\", np.round(Accuracy_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05f3cc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.836 (0.057)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "cv = KFold(n_splits=20, random_state=262, shuffle=True)\n",
    "#A = {0, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1}\n",
    "for i in range(5,6):\n",
    "    bag = BaggingClassifier(n_estimators=10, max_samples=0.6, max_features=0.9, random_state=262)\n",
    "    # create model\n",
    "    model = bag\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # report performance\n",
    "    print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4afae296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision= 0.953\n",
      "test precision= 0.816\n",
      "train f1 score= 0.948\n",
      "test f1 score= 0.813\n",
      "train accuracy score= 0.951\n",
      "test accuracy score= 0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "bag.fit(X_train, y_train)\n",
    "y_pred_bag_train = bag.predict(X_train)\n",
    "y_pred_bag_test = bag.predict(X_test)\n",
    "print(\"train precision=\", np.round(metrics.precision_score(y_train, y_pred_bag_train, average='macro'),3))\n",
    "print(\"test precision=\", np.round(metrics.precision_score(y_test, y_pred_bag_test, average='macro'),3))\n",
    "f1_train = f1_score(y_train, y_pred_bag_train, average='macro')\n",
    "f1_test = f1_score(y_test, y_pred_bag_test, average='macro')\n",
    "print(\"train f1 score=\", np.round(f1_train,3))\n",
    "print(\"test f1 score=\", np.round(f1_test,3))\n",
    "Accuracy_train = accuracy_score(y_train, y_pred_bag_train)\n",
    "Accuracy_test = accuracy_score(y_test, y_pred_bag_test)\n",
    "print(\"train accuracy score=\", np.round(Accuracy_train,3))\n",
    "print(\"test accuracy score=\", np.round(Accuracy_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "98bb0d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8aedf107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 1ms/step - loss: 0.6744 - accuracy: 0.6111\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 879us/step - loss: 0.6221 - accuracy: 0.6397\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.6067 - accuracy: 0.6582\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.5816 - accuracy: 0.7222\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.5615 - accuracy: 0.7138\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.5514 - accuracy: 0.7306\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 608us/step - loss: 0.5324 - accuracy: 0.7492\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.5368 - accuracy: 0.7492\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.5118 - accuracy: 0.7593\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 812us/step - loss: 0.5361 - accuracy: 0.7576\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.5173 - accuracy: 0.7458\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.5133 - accuracy: 0.7576\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.5113 - accuracy: 0.7660\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.5021 - accuracy: 0.7525\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4908 - accuracy: 0.7778\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.5068 - accuracy: 0.7542\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4931 - accuracy: 0.7710\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.5019 - accuracy: 0.7643\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4919 - accuracy: 0.7862\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.5028 - accuracy: 0.7593\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4823 - accuracy: 0.7896\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4765 - accuracy: 0.7710\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4933 - accuracy: 0.7811\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4867 - accuracy: 0.7710\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4736 - accuracy: 0.7710\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4827 - accuracy: 0.7828\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4935 - accuracy: 0.7626\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4823 - accuracy: 0.7879\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.90 - 0s 778us/step - loss: 0.4683 - accuracy: 0.7811\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4647 - accuracy: 0.7727\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.5011 - accuracy: 0.7946\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4567 - accuracy: 0.7879\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4862 - accuracy: 0.7879\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4769 - accuracy: 0.7896\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4806 - accuracy: 0.7845\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 828us/step - loss: 0.4842 - accuracy: 0.7778\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4816 - accuracy: 0.7929\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4740 - accuracy: 0.7862\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4736 - accuracy: 0.7896\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4640 - accuracy: 0.8064\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4671 - accuracy: 0.8047\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4747 - accuracy: 0.7828\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4734 - accuracy: 0.7896\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4758 - accuracy: 0.7912\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.70 - 0s 744us/step - loss: 0.4923 - accuracy: 0.7946\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4630 - accuracy: 0.7912\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4742 - accuracy: 0.7811\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4724 - accuracy: 0.7862\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.80 - 0s 778us/step - loss: 0.4600 - accuracy: 0.7896\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4696 - accuracy: 0.8013\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4700 - accuracy: 0.8047\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4492 - accuracy: 0.7946\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4600 - accuracy: 0.7929\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4525 - accuracy: 0.7879\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4616 - accuracy: 0.8047\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4623 - accuracy: 0.8030\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4793 - accuracy: 0.7896\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 702us/step - loss: 0.4474 - accuracy: 0.7896\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4400 - accuracy: 0.7980\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.4498 - accuracy: 0.7963\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4668 - accuracy: 0.7946\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4610 - accuracy: 0.7946\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 777us/step - loss: 0.4773 - accuracy: 0.8064\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4581 - accuracy: 0.7896\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 810us/step - loss: 0.4814 - accuracy: 0.7912\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 795us/step - loss: 0.4310 - accuracy: 0.8047\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4517 - accuracy: 0.8114\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.90 - 0s 744us/step - loss: 0.4593 - accuracy: 0.7980\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4587 - accuracy: 0.8013\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4532 - accuracy: 0.8030\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4655 - accuracy: 0.8064\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 828us/step - loss: 0.4643 - accuracy: 0.7946\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 726us/step - loss: 0.4449 - accuracy: 0.7997\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5546 - accuracy: 0.70 - 0s 677us/step - loss: 0.4456 - accuracy: 0.7980\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7963\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 829us/step - loss: 0.4555 - accuracy: 0.8013\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4428 - accuracy: 0.8013\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4437 - accuracy: 0.8148\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 677us/step - loss: 0.4380 - accuracy: 0.7946\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4493 - accuracy: 0.7929\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4662 - accuracy: 0.8013\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 692us/step - loss: 0.4384 - accuracy: 0.8098\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4556 - accuracy: 0.7946\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 845us/step - loss: 0.4455 - accuracy: 0.7963\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4604 - accuracy: 0.7912\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 743us/step - loss: 0.4580 - accuracy: 0.7963\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4484 - accuracy: 0.8148\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4517 - accuracy: 0.8013\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4312 - accuracy: 0.8266\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4462 - accuracy: 0.7997\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4549 - accuracy: 0.7896\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4657 - accuracy: 0.8013\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 760us/step - loss: 0.4458 - accuracy: 0.8098\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4463 - accuracy: 0.8064\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4623 - accuracy: 0.8030\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4393 - accuracy: 0.8047\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4467 - accuracy: 0.8098\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4281 - accuracy: 0.8114\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4525 - accuracy: 0.7963\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4400 - accuracy: 0.8030\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.4323 - accuracy: 0.8131\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2996 - accuracy: 1.00 - 0s 829us/step - loss: 0.4568 - accuracy: 0.7997\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 846us/step - loss: 0.4387 - accuracy: 0.8148\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 846us/step - loss: 0.4407 - accuracy: 0.8199\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4589 - accuracy: 0.8081\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4269 - accuracy: 0.8114\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 812us/step - loss: 0.4495 - accuracy: 0.8030\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 930us/step - loss: 0.4414 - accuracy: 0.8064\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 845us/step - loss: 0.4268 - accuracy: 0.8199\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.4453 - accuracy: 0.8047\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4446 - accuracy: 0.8114\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 812us/step - loss: 0.4595 - accuracy: 0.8013\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 777us/step - loss: 0.4368 - accuracy: 0.8064\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 845us/step - loss: 0.4511 - accuracy: 0.8215\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4414 - accuracy: 0.8047\n",
      "Epoch 116/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4226 - accuracy: 0.8165\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 795us/step - loss: 0.4499 - accuracy: 0.8098\n",
      "Epoch 118/300\n",
      "60/60 [==============================] - 0s 845us/step - loss: 0.4385 - accuracy: 0.8165\n",
      "Epoch 119/300\n",
      "60/60 [==============================] - 0s 913us/step - loss: 0.4439 - accuracy: 0.8131\n",
      "Epoch 120/300\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.4353 - accuracy: 0.8199\n",
      "Epoch 121/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4476 - accuracy: 0.8131\n",
      "Epoch 122/300\n",
      "60/60 [==============================] - 0s 812us/step - loss: 0.4259 - accuracy: 0.8064\n",
      "Epoch 123/300\n",
      "60/60 [==============================] - 0s 896us/step - loss: 0.4550 - accuracy: 0.8047\n",
      "Epoch 124/300\n",
      "60/60 [==============================] - 0s 879us/step - loss: 0.4222 - accuracy: 0.8081\n",
      "Epoch 125/300\n",
      "60/60 [==============================] - 0s 828us/step - loss: 0.4554 - accuracy: 0.8064\n",
      "Epoch 126/300\n",
      "60/60 [==============================] - 0s 828us/step - loss: 0.4422 - accuracy: 0.8047\n",
      "Epoch 127/300\n",
      "60/60 [==============================] - 0s 845us/step - loss: 0.4372 - accuracy: 0.8098\n",
      "Epoch 128/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4446 - accuracy: 0.8030\n",
      "Epoch 129/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4345 - accuracy: 0.8098\n",
      "Epoch 130/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.90 - 0s 744us/step - loss: 0.4440 - accuracy: 0.8148\n",
      "Epoch 131/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.70 - 0s 743us/step - loss: 0.4226 - accuracy: 0.8030\n",
      "Epoch 132/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4316 - accuracy: 0.8047\n",
      "Epoch 133/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4324 - accuracy: 0.7980\n",
      "Epoch 134/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4465 - accuracy: 0.8047\n",
      "Epoch 135/300\n",
      "60/60 [==============================] - 0s 862us/step - loss: 0.4357 - accuracy: 0.8114\n",
      "Epoch 136/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4352 - accuracy: 0.8131\n",
      "Epoch 137/300\n",
      "60/60 [==============================] - 0s 677us/step - loss: 0.4207 - accuracy: 0.8199\n",
      "Epoch 138/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4258 - accuracy: 0.8114\n",
      "Epoch 139/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4274 - accuracy: 0.8098\n",
      "Epoch 140/300\n",
      "60/60 [==============================] - 0s 711us/step - loss: 0.4360 - accuracy: 0.7980\n",
      "Epoch 141/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4442 - accuracy: 0.8098\n",
      "Epoch 142/300\n",
      "60/60 [==============================] - 0s 829us/step - loss: 0.4324 - accuracy: 0.8081\n",
      "Epoch 143/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4417 - accuracy: 0.8148\n",
      "Epoch 144/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4220 - accuracy: 0.8148\n",
      "Epoch 145/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4204 - accuracy: 0.8131\n",
      "Epoch 146/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4214 - accuracy: 0.8215\n",
      "Epoch 147/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.70 - 0s 761us/step - loss: 0.4267 - accuracy: 0.8199\n",
      "Epoch 148/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4277 - accuracy: 0.8098\n",
      "Epoch 149/300\n",
      "60/60 [==============================] - 0s 777us/step - loss: 0.4271 - accuracy: 0.8064\n",
      "Epoch 150/300\n",
      "60/60 [==============================] - 0s 879us/step - loss: 0.4298 - accuracy: 0.8081\n",
      "Epoch 151/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4296 - accuracy: 0.8131\n",
      "Epoch 152/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4436 - accuracy: 0.8114\n",
      "Epoch 153/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4366 - accuracy: 0.8182\n",
      "Epoch 154/300\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.4367 - accuracy: 0.8232\n",
      "Epoch 155/300\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.4630 - accuracy: 0.8114\n",
      "Epoch 156/300\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.4422 - accuracy: 0.7997\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 846us/step - loss: 0.4393 - accuracy: 0.8215\n",
      "Epoch 158/300\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.4244 - accuracy: 0.8131\n",
      "Epoch 159/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4173 - accuracy: 0.8266\n",
      "Epoch 160/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.70 - 0s 727us/step - loss: 0.4135 - accuracy: 0.8081\n",
      "Epoch 161/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4179 - accuracy: 0.8182\n",
      "Epoch 162/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4289 - accuracy: 0.8215\n",
      "Epoch 163/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4384 - accuracy: 0.8182\n",
      "Epoch 164/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4291 - accuracy: 0.8165\n",
      "Epoch 165/300\n",
      "60/60 [==============================] - 0s 762us/step - loss: 0.4203 - accuracy: 0.8114\n",
      "Epoch 166/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4368 - accuracy: 0.8114\n",
      "Epoch 167/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4355 - accuracy: 0.8114\n",
      "Epoch 168/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4507 - accuracy: 0.8114\n",
      "Epoch 169/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4342 - accuracy: 0.8148\n",
      "Epoch 170/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4261 - accuracy: 0.8182\n",
      "Epoch 171/300\n",
      "60/60 [==============================] - 0s 711us/step - loss: 0.4371 - accuracy: 0.8165\n",
      "Epoch 172/300\n",
      "60/60 [==============================] - 0s 694us/step - loss: 0.4220 - accuracy: 0.8047\n",
      "Epoch 173/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4421 - accuracy: 0.8182\n",
      "Epoch 174/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4328 - accuracy: 0.8114\n",
      "Epoch 175/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4412 - accuracy: 0.8064\n",
      "Epoch 176/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4267 - accuracy: 0.8114\n",
      "Epoch 177/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4305 - accuracy: 0.8165\n",
      "Epoch 178/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4173 - accuracy: 0.8131\n",
      "Epoch 179/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4256 - accuracy: 0.8182\n",
      "Epoch 180/300\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.4492 - accuracy: 0.8098\n",
      "Epoch 181/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4198 - accuracy: 0.8148\n",
      "Epoch 182/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4277 - accuracy: 0.8081\n",
      "Epoch 183/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4295 - accuracy: 0.8081\n",
      "Epoch 184/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4254 - accuracy: 0.8064\n",
      "Epoch 185/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4302 - accuracy: 0.8131\n",
      "Epoch 186/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4169 - accuracy: 0.8215\n",
      "Epoch 187/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4330 - accuracy: 0.8131\n",
      "Epoch 188/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4275 - accuracy: 0.8148\n",
      "Epoch 189/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4431 - accuracy: 0.8098\n",
      "Epoch 190/300\n",
      "60/60 [==============================] - 0s 794us/step - loss: 0.4261 - accuracy: 0.8114\n",
      "Epoch 191/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4296 - accuracy: 0.8131\n",
      "Epoch 192/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4284 - accuracy: 0.8098\n",
      "Epoch 193/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4346 - accuracy: 0.8064\n",
      "Epoch 194/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4398 - accuracy: 0.8064\n",
      "Epoch 195/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4394 - accuracy: 0.8081\n",
      "Epoch 196/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 1.00 - 0s 744us/step - loss: 0.4305 - accuracy: 0.8148\n",
      "Epoch 197/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4330 - accuracy: 0.8098\n",
      "Epoch 198/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4304 - accuracy: 0.8081\n",
      "Epoch 199/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4091 - accuracy: 0.8215\n",
      "Epoch 200/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4231 - accuracy: 0.8114\n",
      "Epoch 201/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4141 - accuracy: 0.8148\n",
      "Epoch 202/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4231 - accuracy: 0.8148\n",
      "Epoch 203/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4200 - accuracy: 0.8131\n",
      "Epoch 204/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4299 - accuracy: 0.8148\n",
      "Epoch 205/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4227 - accuracy: 0.8199\n",
      "Epoch 206/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4007 - accuracy: 0.8215\n",
      "Epoch 207/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4135 - accuracy: 0.8232\n",
      "Epoch 208/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4127 - accuracy: 0.8165\n",
      "Epoch 209/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4189 - accuracy: 0.8249\n",
      "Epoch 210/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4258 - accuracy: 0.8165\n",
      "Epoch 211/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4234 - accuracy: 0.8249\n",
      "Epoch 212/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4200 - accuracy: 0.8232\n",
      "Epoch 213/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4266 - accuracy: 0.8131\n",
      "Epoch 214/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.90 - 0s 727us/step - loss: 0.4282 - accuracy: 0.8232\n",
      "Epoch 215/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4188 - accuracy: 0.8232\n",
      "Epoch 216/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4182 - accuracy: 0.8249\n",
      "Epoch 217/300\n",
      "60/60 [==============================] - 0s 625us/step - loss: 0.4310 - accuracy: 0.8131\n",
      "Epoch 218/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4228 - accuracy: 0.8215\n",
      "Epoch 219/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4172 - accuracy: 0.8182\n",
      "Epoch 220/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4245 - accuracy: 0.8064\n",
      "Epoch 221/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4235 - accuracy: 0.8148\n",
      "Epoch 222/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4298 - accuracy: 0.8148\n",
      "Epoch 223/300\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.4282 - accuracy: 0.8148\n",
      "Epoch 224/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4314 - accuracy: 0.8114\n",
      "Epoch 225/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4242 - accuracy: 0.8283\n",
      "Epoch 226/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4283 - accuracy: 0.8131\n",
      "Epoch 227/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4239 - accuracy: 0.7997\n",
      "Epoch 228/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4151 - accuracy: 0.8215\n",
      "Epoch 229/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4255 - accuracy: 0.8182\n",
      "Epoch 230/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4094 - accuracy: 0.8266\n",
      "Epoch 231/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4188 - accuracy: 0.8266\n",
      "Epoch 232/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4209 - accuracy: 0.8215\n",
      "Epoch 233/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4275 - accuracy: 0.8013\n",
      "Epoch 234/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4153 - accuracy: 0.8131\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 710us/step - loss: 0.4330 - accuracy: 0.8098\n",
      "Epoch 236/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4121 - accuracy: 0.8249\n",
      "Epoch 237/300\n",
      "60/60 [==============================] - 0s 863us/step - loss: 0.4201 - accuracy: 0.8266\n",
      "Epoch 238/300\n",
      "60/60 [==============================] - 0s 896us/step - loss: 0.4313 - accuracy: 0.8098\n",
      "Epoch 239/300\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.4248 - accuracy: 0.8148\n",
      "Epoch 240/300\n",
      "60/60 [==============================] - 0s 795us/step - loss: 0.4025 - accuracy: 0.8266\n",
      "Epoch 241/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4131 - accuracy: 0.8367\n",
      "Epoch 242/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4321 - accuracy: 0.8131\n",
      "Epoch 243/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.90 - 0s 693us/step - loss: 0.4259 - accuracy: 0.8047\n",
      "Epoch 244/300\n",
      "60/60 [==============================] - 0s 677us/step - loss: 0.4305 - accuracy: 0.8131\n",
      "Epoch 245/300\n",
      "60/60 [==============================] - 0s 677us/step - loss: 0.4222 - accuracy: 0.8098\n",
      "Epoch 246/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4083 - accuracy: 0.8148\n",
      "Epoch 247/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4178 - accuracy: 0.8148\n",
      "Epoch 248/300\n",
      "60/60 [==============================] - 0s 694us/step - loss: 0.4170 - accuracy: 0.8316\n",
      "Epoch 249/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4183 - accuracy: 0.8131\n",
      "Epoch 250/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4010 - accuracy: 0.8266\n",
      "Epoch 251/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4205 - accuracy: 0.8249\n",
      "Epoch 252/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4310 - accuracy: 0.8182\n",
      "Epoch 253/300\n",
      "60/60 [==============================] - 0s 677us/step - loss: 0.4193 - accuracy: 0.8182\n",
      "Epoch 254/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4067 - accuracy: 0.8266\n",
      "Epoch 255/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4097 - accuracy: 0.8401\n",
      "Epoch 256/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4206 - accuracy: 0.8148\n",
      "Epoch 257/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4239 - accuracy: 0.8215\n",
      "Epoch 258/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4246 - accuracy: 0.8165\n",
      "Epoch 259/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4117 - accuracy: 0.8215\n",
      "Epoch 260/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4162 - accuracy: 0.8316\n",
      "Epoch 261/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4185 - accuracy: 0.8148\n",
      "Epoch 262/300\n",
      "60/60 [==============================] - 0s 624us/step - loss: 0.4147 - accuracy: 0.8182\n",
      "Epoch 263/300\n",
      "60/60 [==============================] - 0s 677us/step - loss: 0.4285 - accuracy: 0.8182\n",
      "Epoch 264/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4206 - accuracy: 0.8199\n",
      "Epoch 265/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4290 - accuracy: 0.8131\n",
      "Epoch 266/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4175 - accuracy: 0.8215\n",
      "Epoch 267/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4198 - accuracy: 0.8131\n",
      "Epoch 268/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4140 - accuracy: 0.8266\n",
      "Epoch 269/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4313 - accuracy: 0.8199\n",
      "Epoch 270/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4010 - accuracy: 0.8232\n",
      "Epoch 271/300\n",
      "60/60 [==============================] - 0s 658us/step - loss: 0.4063 - accuracy: 0.8333\n",
      "Epoch 272/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4191 - accuracy: 0.8249\n",
      "Epoch 273/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4127 - accuracy: 0.8131\n",
      "Epoch 274/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4186 - accuracy: 0.8182\n",
      "Epoch 275/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4150 - accuracy: 0.8249\n",
      "Epoch 276/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4201 - accuracy: 0.8266\n",
      "Epoch 277/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4375 - accuracy: 0.8165\n",
      "Epoch 278/300\n",
      "60/60 [==============================] - 0s 727us/step - loss: 0.4146 - accuracy: 0.8249\n",
      "Epoch 279/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4178 - accuracy: 0.8232\n",
      "Epoch 280/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4158 - accuracy: 0.8182\n",
      "Epoch 281/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4312 - accuracy: 0.8131\n",
      "Epoch 282/300\n",
      "60/60 [==============================] - 0s 625us/step - loss: 0.4184 - accuracy: 0.8148\n",
      "Epoch 283/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4173 - accuracy: 0.8182\n",
      "Epoch 284/300\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.4310 - accuracy: 0.8131\n",
      "Epoch 285/300\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.4196 - accuracy: 0.8199\n",
      "Epoch 286/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4346 - accuracy: 0.8098\n",
      "Epoch 287/300\n",
      "60/60 [==============================] - 0s 845us/step - loss: 0.3993 - accuracy: 0.8131\n",
      "Epoch 288/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4144 - accuracy: 0.8081\n",
      "Epoch 289/300\n",
      "60/60 [==============================] - 0s 828us/step - loss: 0.4306 - accuracy: 0.8114\n",
      "Epoch 290/300\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.4098 - accuracy: 0.8114\n",
      "Epoch 291/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4100 - accuracy: 0.8300\n",
      "Epoch 292/300\n",
      "60/60 [==============================] - 0s 710us/step - loss: 0.4065 - accuracy: 0.8350\n",
      "Epoch 293/300\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.4309 - accuracy: 0.8114\n",
      "Epoch 294/300\n",
      "60/60 [==============================] - 0s 744us/step - loss: 0.4259 - accuracy: 0.8064\n",
      "Epoch 295/300\n",
      "60/60 [==============================] - 0s 777us/step - loss: 0.3783 - accuracy: 0.8316\n",
      "Epoch 296/300\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.4183 - accuracy: 0.8215\n",
      "Epoch 297/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4131 - accuracy: 0.8283\n",
      "Epoch 298/300\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4222 - accuracy: 0.8131\n",
      "Epoch 299/300\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.4264 - accuracy: 0.8182\n",
      "Epoch 300/300\n",
      "60/60 [==============================] - 0s 761us/step - loss: 0.4407 - accuracy: 0.8215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2814642f1f0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "### Initializing the ANN\n",
    "ann = tf.keras.models.Sequential()\n",
    "### Adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
    "ann.add(Dropout(0.3))\n",
    "ann.add(tf.keras.layers.Dense(units=40, activation='relu'))\n",
    "ann.add(Dropout(0.3))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "### Compiling the ANN\n",
    "ann.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "### Training the ANN on the Training set\n",
    "ann.fit(X_train, y_train, batch_size = 10, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b7081844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6915612599206349\n",
      "0.6677096370463078\n",
      "0.815040852929454\n",
      "0.8063258451619436\n",
      "train accuracy score= 0.832\n",
      "test accuracy score= 0.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "y_pred_train = np.round(ann.predict(X_train),0)\n",
    "y_pred_test = np.round(ann.predict(X_test),0)\n",
    "precision_test = average_precision_score(y_test, y_pred_test)\n",
    "precision_train = average_precision_score(y_train, y_pred_train)\n",
    "print(precision_train)\n",
    "print(precision_test)\n",
    "f1_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "print(f1_train)\n",
    "print(f1_test)\n",
    "Accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "Accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"train accuracy score=\", np.round(Accuracy_train,3))\n",
    "print(\"test accuracy score=\", np.round(Accuracy_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0d975163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from keras.layers import Dropout\n",
    "def build_classifier():\n",
    "    ### Initializing the ANN\n",
    "    ann_p = tf.keras.models.Sequential()\n",
    "    ### Adding the input layer and the hidden layers\n",
    "    ann_p.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
    "    ann_p.add(Dropout(0.2))\n",
    "    ann_p.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
    "    ann_p.add(Dropout(0.6))\n",
    "    ann_p.add(tf.keras.layers.Dense(units=20, activation='elu'))\n",
    "    ann_p.add(Dropout(0.3))\n",
    "    ann_p.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    ### Compiling the ANN\n",
    "    ann_p.compile(optimizer = 'RMSprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return ann_p\n",
    "ann_p = KerasClassifier(build_fn = build_classifier, batch_size = 8, epochs = 300, \n",
    "                        validation_data=(X_test,y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0c83eec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   58.8s remaining:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81512606 0.78991598 0.8487395  0.84033614 0.81355929]\n",
      "[0.8215353965759278] [0.020966721128898667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.5s finished\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator=ann_p, X=X_train, y=y_train, cv=5, n_jobs=-1, verbose=1)\n",
    "print(accuracies)\n",
    "mean = accuracies.mean()\n",
    "std = accuracies.std()\n",
    "print([mean], [std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "771252c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n",
      "0.758\n",
      "train f1 score= 0.906\n",
      "test f1 score= 0.801\n",
      "train accuracy score= 0.912\n",
      "test accuracy score= 0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='rbf', degree =2, gamma = 0.3, C = 1200, max_iter=-1, random_state = 262) \n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred_svm_train = clf.predict(X_train)\n",
    "y_pred_svm_test = clf.predict(X_test)\n",
    "print(np.round(metrics.precision_score(y_train, y_pred_svm_train),3))\n",
    "print(np.round(metrics.precision_score(y_test, y_pred_svm_test),3))\n",
    "Accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "Accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
    "f1_train = f1_score(y_train, y_pred_svm_train, average='macro')\n",
    "f1_test = f1_score(y_test, y_pred_svm_test, average='macro')\n",
    "print(\"train f1 score=\", np.round(f1_train,3))\n",
    "print(\"test f1 score=\", np.round(f1_test,3))\n",
    "print(\"train accuracy score=\", np.round(Accuracy_train,3))\n",
    "print(\"test accuracy score=\", np.round(Accuracy_test,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09d2de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9159663865546218\n",
      "0.9545454545454546\n",
      "train f1 score= 0.744\n",
      "test f1 score= 0.732\n",
      "train accuracy score= 0.79\n",
      "test accuracy score= 0.788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Create a svm Classifier#\n",
    "clfrf=RandomForestClassifier(n_estimators=200, criterion=\"entropy\", max_depth=5,\n",
    "    min_samples_split=11, min_samples_leaf=1, min_weight_fraction_leaf=0.05, max_features='auto', max_leaf_nodes=10,\n",
    "    min_impurity_decrease=0.06, bootstrap=True, oob_score=False, n_jobs=-1,\n",
    "    verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.02, max_samples=80, random_state = 262)\n",
    "\n",
    "# Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clfrf.fit(X_train,y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred_rf_train = clfrf.predict(X_train)\n",
    "y_pred_rf_test = clfrf.predict(X_test)\n",
    "print(metrics.precision_score(y_train, y_pred_rf_train))\n",
    "print(metrics.precision_score(y_test, y_pred_rf_test))\n",
    "f1_train = f1_score(y_train, y_pred_rf_train, average='macro')\n",
    "f1_test = f1_score(y_test, y_pred_rf_test, average='macro')\n",
    "print(\"train f1 score=\", np.round(f1_train,3))\n",
    "print(\"test f1 score=\", np.round(f1_test,3))\n",
    "Accuracy_train = accuracy_score(y_train, y_pred_rf_train)\n",
    "Accuracy_test = accuracy_score(y_test, y_pred_rf_test)\n",
    "print(\"train accuracy score=\", np.round(Accuracy_train,3))\n",
    "print(\"test accuracy score=\", np.round(Accuracy_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13fb9769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision= 0.982\n",
      "test precision= 0.714\n",
      "train f1 score= 0.978\n",
      "test f1 score= 0.783\n",
      "train accuracy score= 0.98\n",
      "test accuracy score= 0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm_train = lgbm.predict(X_train)\n",
    "y_pred_lgbm_test = lgbm.predict(X_test)\n",
    "print(\"train precision=\", np.round(metrics.precision_score(y_train, y_pred_lgbm_train),3))\n",
    "print(\"test precision=\", np.round(metrics.precision_score(y_test, y_pred_lgbm_test),3))\n",
    "f1_train = f1_score(y_train, y_pred_lgbm_train, average='macro')\n",
    "f1_test = f1_score(y_test, y_pred_lgbm_test, average='macro')\n",
    "print(\"train f1 score=\", np.round(f1_train,3))\n",
    "print(\"test f1 score=\", np.round(f1_test,3))\n",
    "Accuracy_train = accuracy_score(y_train, y_pred_lgbm_train)\n",
    "Accuracy_test = accuracy_score(y_test, y_pred_lgbm_test)\n",
    "print(\"train accuracy score=\", np.round(Accuracy_train,3))\n",
    "print(\"test accuracy score=\", np.round(Accuracy_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfed0379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['330911']\n",
      " ['363272']\n",
      " ['240276']\n",
      " ['315154']\n",
      " ['3101298']\n",
      " ['7538']\n",
      " ['330972']\n",
      " ['248738']\n",
      " ['2657']\n",
      " ['448871']\n",
      " ['349220']\n",
      " ['694']\n",
      " ['21228']\n",
      " ['24065']\n",
      " ['5734']\n",
      " ['2167']\n",
      " ['233734']\n",
      " ['2692']\n",
      " ['23101270']\n",
      " ['2696']\n",
      " ['17603']\n",
      " ['17368']\n",
      " ['17598']\n",
      " ['17597']\n",
      " ['17608']\n",
      " ['53337']\n",
      " ['113509']\n",
      " ['2698']\n",
      " ['113054']\n",
      " ['2662']\n",
      " ['3085']\n",
      " ['31029']\n",
      " ['2315']\n",
      " ['6607']\n",
      " ['13236']\n",
      " ['2682']\n",
      " ['342712']\n",
      " ['315087']\n",
      " ['345768']\n",
      " ['1601']\n",
      " ['349256']\n",
      " ['113778']\n",
      " ['3101263']\n",
      " ['237249']\n",
      " ['11753']\n",
      " ['23101291']\n",
      " ['17594']\n",
      " ['370374']\n",
      " ['11813']\n",
      " ['37671']\n",
      " ['13695']\n",
      " ['2168']\n",
      " ['29105']\n",
      " ['19950']\n",
      " ['32861']\n",
      " ['382652']\n",
      " ['349230']\n",
      " ['348122']\n",
      " ['386525']\n",
      " ['17608']\n",
      " ['349232']\n",
      " ['237216']\n",
      " ['347090']\n",
      " ['334914']\n",
      " ['17608']\n",
      " ['13534']\n",
      " ['330963']\n",
      " ['113796']\n",
      " ['2543']\n",
      " ['19950']\n",
      " ['382653']\n",
      " ['349211']\n",
      " ['3101297']\n",
      " ['17562']\n",
      " ['113503']\n",
      " ['113503']\n",
      " ['359306']\n",
      " ['11770']\n",
      " ['248744']\n",
      " ['368702']\n",
      " ['2678']\n",
      " ['17483']\n",
      " ['19924']\n",
      " ['349238']\n",
      " ['240261']\n",
      " ['2660']\n",
      " ['330844']\n",
      " ['431416']\n",
      " ['364856']\n",
      " ['29103']\n",
      " ['347072']\n",
      " ['345498']\n",
      " ['12750']\n",
      " ['376563']\n",
      " ['13905']\n",
      " ['350033']\n",
      " ['19877']\n",
      " ['23101268']\n",
      " ['347471']\n",
      " ['53338']\n",
      " ['11778']\n",
      " ['228414']\n",
      " ['365235']\n",
      " ['347070']\n",
      " ['2625']\n",
      " ['4001']\n",
      " ['330920']\n",
      " ['383162']\n",
      " ['3410']\n",
      " ['248734']\n",
      " ['237734']\n",
      " ['330968']\n",
      " ['17531']\n",
      " ['329944']\n",
      " ['17483']\n",
      " ['2680']\n",
      " ['2681']\n",
      " ['9549']\n",
      " ['13050']\n",
      " ['29037']\n",
      " ['33595']\n",
      " ['367227']\n",
      " ['13236']\n",
      " ['392095']\n",
      " ['368783']\n",
      " ['371362']\n",
      " ['350045']\n",
      " ['367226']\n",
      " ['211535']\n",
      " ['342441']\n",
      " ['369943']\n",
      " ['113780']\n",
      " ['4133']\n",
      " ['2621']\n",
      " ['349226']\n",
      " ['350409']\n",
      " ['2656']\n",
      " ['248659']\n",
      " ['392083']\n",
      " ['2144']\n",
      " ['2144']\n",
      " ['113781']\n",
      " ['17608']\n",
      " ['244358']\n",
      " ['17475']\n",
      " ['345763']\n",
      " ['17463']\n",
      " ['423568']\n",
      " ['113791']\n",
      " ['250651']\n",
      " ['11767']\n",
      " ['349255']\n",
      " ['3701']\n",
      " ['350405']\n",
      " ['347077']\n",
      " ['752']\n",
      " ['17483']\n",
      " ['347469']\n",
      " ['110489']\n",
      " ['3101315']\n",
      " ['335432']\n",
      " ['2650']\n",
      " ['220844']\n",
      " ['343271']\n",
      " ['237393']\n",
      " ['315153']\n",
      " ['17591']\n",
      " ['6608']\n",
      " ['17770']\n",
      " ['7548']\n",
      " ['251']\n",
      " ['2670']\n",
      " ['347072']\n",
      " ['2673']\n",
      " ['347077']\n",
      " ['29750']\n",
      " ['33112']\n",
      " ['11778']\n",
      " ['230136']\n",
      " ['17756']\n",
      " ['233478']\n",
      " ['17756']\n",
      " ['113773']\n",
      " ['7935']\n",
      " ['17558']\n",
      " ['239059']\n",
      " ['2']\n",
      " ['448873']\n",
      " ['2343']\n",
      " ['28221']\n",
      " ['226875']\n",
      " ['111163']\n",
      " ['5851']\n",
      " ['235509']\n",
      " ['28220']\n",
      " ['347465']\n",
      " ['16966']\n",
      " ['347066']\n",
      " ['31030']\n",
      " ['65305']\n",
      " ['36568']\n",
      " ['347080']\n",
      " ['17757']\n",
      " ['26360']\n",
      " ['34050']\n",
      " ['12998']\n",
      " ['9232']\n",
      " ['28034']\n",
      " ['17613']\n",
      " ['349250']\n",
      " ['4001']\n",
      " ['3101308']\n",
      " ['14879']\n",
      " ['24065']\n",
      " ['347091']\n",
      " ['113038']\n",
      " ['330924']\n",
      " ['36928']\n",
      " ['113503']\n",
      " ['32302']\n",
      " ['2148']\n",
      " ['342684']\n",
      " ['14266']\n",
      " ['350053']\n",
      " ['17606']\n",
      " ['2661']\n",
      " ['350054']\n",
      " ['370368']\n",
      " ['6212']\n",
      " ['242963']\n",
      " ['220845']\n",
      " ['113795']\n",
      " ['3101266']\n",
      " ['330971']\n",
      " ['17599']\n",
      " ['350416']\n",
      " ['110813']\n",
      " ['2679']\n",
      " ['250650']\n",
      " ['17761']\n",
      " ['112377']\n",
      " ['237789']\n",
      " ['16966']\n",
      " ['3470']\n",
      " ['6607']\n",
      " ['17464']\n",
      " ['13534']\n",
      " ['28220']\n",
      " ['26707']\n",
      " ['2660']\n",
      " ['34651']\n",
      " ['23101284']\n",
      " ['13508']\n",
      " ['7266']\n",
      " ['345775']\n",
      " ['42795']\n",
      " ['43130']\n",
      " ['363611']\n",
      " ['28404']\n",
      " ['345501']\n",
      " ['345572']\n",
      " ['350410']\n",
      " ['29103']\n",
      " ['350405']\n",
      " ['34644']\n",
      " ['349235']\n",
      " ['112051']\n",
      " ['49867']\n",
      " ['239186']\n",
      " ['315095']\n",
      " ['13050']\n",
      " ['368573']\n",
      " ['13508']\n",
      " ['370371']\n",
      " ['2676']\n",
      " ['236853']\n",
      " ['14888']\n",
      " ['2926']\n",
      " ['31352']\n",
      " ['14260']\n",
      " ['315085']\n",
      " ['3101315']\n",
      " ['364859']\n",
      " ['2650']\n",
      " ['370129']\n",
      " ['521175']\n",
      " ['3101314']\n",
      " ['21228']\n",
      " ['2655']\n",
      " ['51478']\n",
      " ['17607']\n",
      " ['382650']\n",
      " ['2652']\n",
      " ['33638']\n",
      " ['345771']\n",
      " ['349202']\n",
      " ['2123']\n",
      " ['2662']\n",
      " ['113801']\n",
      " ['347467']\n",
      " ['347079']\n",
      " ['237735']\n",
      " ['2']\n",
      " ['315092']\n",
      " ['383123']\n",
      " ['112901']\n",
      " ['113781']\n",
      " ['392091']\n",
      " ['12749']\n",
      " ['350026']\n",
      " ['315091']\n",
      " ['2658']\n",
      " ['1588']\n",
      " ['368364']\n",
      " ['17760']\n",
      " ['330631']\n",
      " ['17569']\n",
      " ['28004']\n",
      " ['350408']\n",
      " ['31029']\n",
      " ['347075']\n",
      " ['2654']\n",
      " ['244368']\n",
      " ['113790']\n",
      " ['24160']\n",
      " ['3101309']\n",
      " ['230136']\n",
      " ['17585']\n",
      " ['2003']\n",
      " ['236854']\n",
      " ['33112']\n",
      " ['17580']\n",
      " ['2684']\n",
      " ['2653']\n",
      " ['349229']\n",
      " ['110469']\n",
      " ['244360']\n",
      " ['2675']\n",
      " ['31029']\n",
      " ['2622']\n",
      " ['15185']\n",
      " ['350403']\n",
      " ['2343']\n",
      " ['17755']\n",
      " ['5851']\n",
      " ['348125']\n",
      " ['237670']\n",
      " ['2688']\n",
      " ['248726']\n",
      " ['13528']\n",
      " ['17759']\n",
      " ['13540']\n",
      " ['14879']\n",
      " ['220845']\n",
      " ['2315']\n",
      " ['113044']\n",
      " ['11769']\n",
      " ['1222']\n",
      " ['368402']\n",
      " ['349910']\n",
      " ['2343']\n",
      " ['2079']\n",
      " ['31352']\n",
      " ['315083']\n",
      " ['11765']\n",
      " ['2343']\n",
      " ['2689']\n",
      " ['3101295']\n",
      " ['112378']\n",
      " ['2147']\n",
      " ['28133']\n",
      " ['16966']\n",
      " ['112058']\n",
      " ['248746']\n",
      " ['33638']\n",
      " ['17608']\n",
      " ['315152']\n",
      " ['29107']\n",
      " ['680']\n",
      " ['347077']\n",
      " ['366713']\n",
      " ['330910']\n",
      " ['364498']\n",
      " ['376566']\n",
      " ['2159']\n",
      " ['220845']\n",
      " ['349911']\n",
      " ['244346']\n",
      " ['364858']\n",
      " ['349909']\n",
      " ['12749']\n",
      " ['17592']\n",
      " ['2673']\n",
      " ['30769']\n",
      " ['315153']\n",
      " ['13695']\n",
      " ['371109']\n",
      " ['13567']\n",
      " ['347065']\n",
      " ['21332']\n",
      " ['36928']\n",
      " ['28664']\n",
      " ['112378']\n",
      " ['113059']\n",
      " ['17765']\n",
      " ['2166']\n",
      " ['28666']\n",
      " ['113503']\n",
      " ['334915']\n",
      " ['3101315']\n",
      " ['365237']\n",
      " ['19928']\n",
      " ['347086']\n",
      " ['53236']\n",
      " ['17758']\n",
      " ['3101262']\n",
      " ['359309']\n",
      " ['2668']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "dft = pd.read_csv(\"test.csv\", index_col=0)\n",
    "dft = dft.drop(columns={\"Name\",\"Cabin\"})\n",
    "dft['Ticket'] = dft['Ticket'].str.replace(r'\\D', '')\n",
    "dft = dft.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "print(dft[[\"Ticket\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a881ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass       0\n",
       "Sex          0\n",
       "Age         86\n",
       "SibSp        0\n",
       "Parch        0\n",
       "Ticket       0\n",
       "Fare         1\n",
       "Embarked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in list(dft):\n",
    "    dft[\"Ticket\"]=pd.to_numeric(dft[\"Ticket\"], errors='ignore')\n",
    "dft[\"Ticket\"] = dft[\"Ticket\"].interpolate(method='linear')\n",
    "dft.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f2d3f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  Sex   Age  SibSp  Parch   Ticket      Fare  Embarked\n",
       "PassengerId                                                              \n",
       "892               3    1  34.5      0      0   330911    7.8292         1\n",
       "893               3    0  47.0      1      0   363272    7.0000         2\n",
       "894               2    1  62.0      0      0   240276    9.6875         1\n",
       "895               3    1  27.0      0      0   315154    8.6625         2\n",
       "896               3    0  22.0      1      1  3101298   12.2875         2\n",
       "...             ...  ...   ...    ...    ...      ...       ...       ...\n",
       "1305              3    1   NaN      0      0    53236    8.0500         2\n",
       "1306              1    0  39.0      0      0    17758  108.9000         0\n",
       "1307              3    1  38.5      0      0  3101262    7.2500         2\n",
       "1308              3    1   NaN      0      0   359309    8.0500         2\n",
       "1309              3    1   NaN      1      1     2668   22.3583         0\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "dft['Sex'] = le.fit_transform(dft['Sex'])\n",
    "dft['Embarked'] = le.fit_transform(dft['Embarked'])\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "486abca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.loc[(dft[\"Pclass\"] == 0) & (dft[\"Sex\"] == 0), \"Pclass_Sex\"] = 0  \n",
    "dft.loc[(dft[\"Pclass\"] == 1) & (dft[\"Sex\"] == 0), \"Pclass_Sex\"] = 1  \n",
    "dft.loc[(dft[\"Pclass\"] == 2) & (dft[\"Sex\"] == 0), \"Pclass_Sex\"] = 2\n",
    "dft.loc[(dft[\"Pclass\"] == 3) & (dft[\"Sex\"] == 0), \"Pclass_Sex\"] = 3  \n",
    "dft.loc[(dft[\"Pclass\"] == 0) & (dft[\"Sex\"] == 1), \"Pclass_Sex\"] = 4  \n",
    "dft.loc[(dft[\"Pclass\"] == 1) & (dft[\"Sex\"] == 1), \"Pclass_Sex\"] = 5  \n",
    "dft.loc[(dft[\"Pclass\"] == 2) & (dft[\"Sex\"] == 1), \"Pclass_Sex\"] = 6\n",
    "dft.loc[(dft[\"Pclass\"] == 3) & (dft[\"Sex\"] == 1), \"Pclass_Sex\"] = 7  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab5b9671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 87\n",
      "Missing: 0\n",
      "Mean Accuracy: 1.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# iterative imputation transform for the horse colic dataset\n",
    "from numpy import isnan, mean, std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "# load dataset\n",
    "# split into input and output elements\n",
    "data = dft.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 9]\n",
    "X, y = data[:, ix], data[:, 8]\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "# define imputer\n",
    "imputer = IterativeImputer()\n",
    "#define modeling pipeline\n",
    "## model = svm.SVC(kernel='rbf', degree =3, gamma = 0.01, C = 100, max_iter=-1, random_state = 262)\n",
    "model = BaggingRegressor()\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "dft = imputer.transform(X)\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(dft).flatten()))\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "# define model evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7fc07b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass_Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330911.0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>363272.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240276.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315154.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3101298.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.250671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53236.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17758.0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3101262.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.256597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359309.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.489061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Ticket      Fare  Embarked  \\\n",
       "0       3.0  1.0  34.500000    0.0    0.0   330911.0    7.8292       1.0   \n",
       "1       3.0  0.0  47.000000    1.0    0.0   363272.0    7.0000       2.0   \n",
       "2       2.0  1.0  62.000000    0.0    0.0   240276.0    9.6875       1.0   \n",
       "3       3.0  1.0  27.000000    0.0    0.0   315154.0    8.6625       2.0   \n",
       "4       3.0  0.0  22.000000    1.0    1.0  3101298.0   12.2875       2.0   \n",
       "..      ...  ...        ...    ...    ...        ...       ...       ...   \n",
       "413     3.0  1.0  25.250671    0.0    0.0    53236.0    8.0500       2.0   \n",
       "414     1.0  0.0  39.000000    0.0    0.0    17758.0  108.9000       0.0   \n",
       "415     3.0  1.0  38.500000    0.0    0.0  3101262.0    7.2500       2.0   \n",
       "416     3.0  1.0  25.256597    0.0    0.0   359309.0    8.0500       2.0   \n",
       "417     3.0  1.0  23.489061    1.0    1.0     2668.0   22.3583       0.0   \n",
       "\n",
       "     Pclass_Sex  \n",
       "0           7.0  \n",
       "1           3.0  \n",
       "2           6.0  \n",
       "3           7.0  \n",
       "4           3.0  \n",
       "..          ...  \n",
       "413         7.0  \n",
       "414         1.0  \n",
       "415         7.0  \n",
       "416         7.0  \n",
       "417         7.0  \n",
       "\n",
       "[418 rows x 9 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.DataFrame(dft)\n",
    "dft.columns = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\", \"Embarked\",\"Pclass_Sex\"]\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcf3a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass_Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330911.0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>363272.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240276.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315154.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3101298.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53236.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17758.0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3101262.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359309.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex  Age  SibSp  Parch     Ticket      Fare  Embarked  Pclass_Sex\n",
       "0       3.0  1.0  4.0    0.0    0.0   330911.0    7.8292       1.0         7.0\n",
       "1       3.0  0.0  5.0    1.0    0.0   363272.0    7.0000       2.0         3.0\n",
       "2       2.0  1.0  5.0    0.0    0.0   240276.0    9.6875       1.0         6.0\n",
       "3       3.0  1.0  3.0    0.0    0.0   315154.0    8.6625       2.0         7.0\n",
       "4       3.0  0.0  2.0    1.0    1.0  3101298.0   12.2875       2.0         3.0\n",
       "..      ...  ...  ...    ...    ...        ...       ...       ...         ...\n",
       "413     3.0  1.0  3.0    0.0    0.0    53236.0    8.0500       2.0         7.0\n",
       "414     1.0  0.0  4.0    0.0    0.0    17758.0  108.9000       0.0         1.0\n",
       "415     3.0  1.0  4.0    0.0    0.0  3101262.0    7.2500       2.0         7.0\n",
       "416     3.0  1.0  3.0    0.0    0.0   359309.0    8.0500       2.0         7.0\n",
       "417     3.0  1.0  2.0    1.0    1.0     2668.0   22.3583       0.0         7.0\n",
       "\n",
       "[418 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.loc[dft[\"Age\"] <= 5, \"Age\"] = 0\n",
    "dft.loc[(dft[\"Age\"] > 5) & (dft[\"Age\"] <= 10), \"Age\"] = 1\n",
    "dft.loc[(dft[\"Age\"] > 10) & (dft[\"Age\"] <= 25), \"Age\"] = 2\n",
    "dft.loc[(dft[\"Age\"] > 25) & (dft[\"Age\"] <= 30), \"Age\"] = 3\n",
    "dft.loc[(dft[\"Age\"] > 30) & (dft[\"Age\"] <= 40), \"Age\"] = 4\n",
    "dft.loc[dft[\"Age\"] > 40, \"Age\"] = 5\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d46b0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft[\"Family\"] = dft[\"SibSp\"] + dft[\"Parch\"]\n",
    "dft.loc[dft[\"Family\"] < 1, \"Family\"] = 0\n",
    "dft.loc[dft[\"Family\"] == 1, \"Family\"] = 1\n",
    "dft.loc[(dft[\"Family\"] > 1) & (dft[\"Family\"] <= 3), \"Family\"] = 2\n",
    "dft.loc[dft[\"Family\"] > 3, \"Family\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ced7769f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7573036 ,  0.12795398, -0.65517416,  0.9487859 , -0.70226867],\n",
       "       [ 1.48874805,  0.18802308, -0.68374272, -0.89297496,  0.31268897],\n",
       "       [ 1.48874805, -0.04028443, -0.59114985,  0.48834568, -0.70226867],\n",
       "       ...,\n",
       "       [ 0.7573036 ,  5.27033221, -0.67512943,  0.9487859 , -0.70226867],\n",
       "       [ 0.02585915,  0.18066689, -0.6475669 ,  0.9487859 , -0.70226867],\n",
       "       [-0.7055853 , -0.48133692, -0.15460073,  0.9487859 ,  1.3276466 ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = dft[[\"Age\",\"Ticket\",\"Fare\",\"Pclass_Sex\",\"Family\"]]\n",
    "dft = stdscl.transform(dft)\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4b7843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = pd.DataFrame(np.round(xgb.predict(dft),0))\n",
    "y_pred_xgb.to_csv(\"xgb_baggingregressor3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3cdca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
